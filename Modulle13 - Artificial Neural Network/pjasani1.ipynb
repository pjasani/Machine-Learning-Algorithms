{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 13 - Programming Assignment\n",
    "\n",
    "## Directions\n",
    "\n",
    "1. Change the name of this file to be your JHED id as in `jsmith299.ipynb`. Because sure you use your JHED ID (it's made out of your name and not your student id which is just letters and numbers).\n",
    "2. Make sure the notebook you submit is cleanly and fully executed. I do not grade unexecuted notebooks.\n",
    "3. Submit your notebook back in Blackboard where you downloaded this file.\n",
    "\n",
    "*Provide the output **exactly** as requested*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Problem\n",
    "\n",
    "When we last left our agent in Module 4, it was wandering around a world filled with plains, forests, swamps, hills and mountains. This presupposes a map with known terrain:\n",
    "\n",
    "```\n",
    "......\n",
    "...**.\n",
    "...***\n",
    "..^...\n",
    "..~^..\n",
    "```\n",
    "\n",
    "but what if all we know is that we have some area of interest, that we've reduced to a GPS grid:\n",
    "\n",
    "```\n",
    "??????\n",
    "??????\n",
    "??????\n",
    "??????\n",
    "??????\n",
    "```\n",
    "\n",
    "and the agent has to determine what kind of terrain is to the left, front and right of it?\n",
    "\n",
    "Assuming the agent has a very simple visual sensor that constructs a 4x4 grayscale image for each of the three directions, it might it could see something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "plain =  [0.0, 0.0, 0.0, 0.0,0.0, 0.0, 0.0, 0.0,0.0, 0.0, 0.0, 0.0,1.0, 1.0, 1.0, 1.0]\n",
    "forest = [0.0, 1.0, 0.0, 0.0,1.0, 1.0, 1.0, 0.0,1.0, 1.0, 1.0, 1.0,0.0, 1.0, 0.0, 0.0]\n",
    "hills =  [0.0, 0.0, 0.0, 0.0,0.0, 0.0, 1.0, 0.0,0.0, 1.0, 1.0, 1.0,1.0, 1.0, 1.0, 1.0]\n",
    "swamp =  [0.0, 0.0, 0.0, 0.0,0.0, 0.0, 0.0, 0.0,1.0, 0.0, 1.0, 0.0,1.0, 1.0, 1.0, 1.0]\n",
    "\n",
    "figure = plt.figure(figsize=(20,6))\n",
    "\n",
    "axes = figure.add_subplot(1, 3, 1)\n",
    "pixels = np.array([255 - p * 255 for p in plain], dtype='uint8')\n",
    "pixels = pixels.reshape((4, 4))\n",
    "axes.set_title( \"Left Camera\")\n",
    "axes.imshow(pixels, cmap='gray')\n",
    "\n",
    "axes = figure.add_subplot(1, 3, 2)\n",
    "pixels = np.array([255 - p * 255 for p in forest], dtype='uint8')\n",
    "pixels = pixels.reshape((4, 4))\n",
    "axes.set_title( \"Front Camera\")\n",
    "axes.imshow(pixels, cmap='gray')\n",
    "\n",
    "axes = figure.add_subplot(1, 3, 3)\n",
    "pixels = np.array([255 - p * 255 for p in hills], dtype='uint8')\n",
    "pixels = pixels.reshape((4, 4))\n",
    "axes.set_title( \"Right Camera\")\n",
    "axes.imshow(pixels, cmap='gray')\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which would be plains, forest and hills respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Assignment\n",
    "\n",
    "In Assignment 12, we applied a logistic regression to determine if something was \"hills\" or \"not hills\". For this programming assignment your task is to write an artificial neural network that determines what kind of terrain it is. This is a multi-class problem.\n",
    "\n",
    "For a starting point, you can refer to Pseudocode and the Self-Check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "As before, we have clean examples of the different types of terrain but based on the location, the registration can be a bit off for some of the types and the visual sensor is often blurry.\n",
    "\n",
    "Here are the clean examples with different registrations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = {\n",
    "    \"plains\": [\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, \"plains\"]\n",
    "    ],\n",
    "    \"forest\": [\n",
    "        [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, \"forest\"],\n",
    "        [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, \"forest\"],\n",
    "        [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, \"forest\"],\n",
    "        [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, \"forest\"]\n",
    "    ],\n",
    "    \"hills\": [\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, \"hills\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, \"hills\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, \"hills\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, \"hills\"]\n",
    "    ],\n",
    "    \"swamp\": [\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, \"swamp\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, \"swamp\"]        \n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function that allows us to view any of these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_sensor_image( data):\n",
    "    figure = plt.figure(figsize=(4,4))\n",
    "    axes = figure.add_subplot(1, 1, 1)\n",
    "    pixels = np.array([255 - p * 255 for p in data[:-1]], dtype='uint8')\n",
    "    pixels = pixels.reshape((4, 4))\n",
    "    axes.set_title( \"Left Camera:\" + data[-1])\n",
    "    axes.imshow(pixels, cmap='gray')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"I think that I shall never see a thing so lovely as a tree.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_sensor_image( clean_data[ \"forest\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_sensor_image( clean_data[\"swamp\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that comes in, however, is noisy. The values are never exactly 0 and 1. In order to mimic this we need a `blur` function.\n",
    "\n",
    "We will assume that noise is normally distributed. For values that should be 0, the noisy values are distributed $N(0.10, 0.05)$. For values should be 1, the noisy values are distributed $N(0.9, 0.10)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur( data):\n",
    "    def apply_noise( value):\n",
    "        if value < 0.5:\n",
    "            v = random.gauss( 0.10, 0.05)\n",
    "            if v < 0.0:\n",
    "                return 0.0\n",
    "            if v > 0.75:\n",
    "                return 0.75\n",
    "            return v\n",
    "        else:\n",
    "            v = random.gauss( 0.90, 0.10)\n",
    "            if v < 0.25:\n",
    "                return 0.25\n",
    "            if v > 1.00:\n",
    "                return 1.00\n",
    "            return v\n",
    "    noisy_readings = [apply_noise( v) for v in data[0:-1]]\n",
    "    return noisy_readings + [data[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how this affects what the agent *actually* sees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_sensor_image( blur( clean_data[\"swamp\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are going to want to write four (4) functions:\n",
    "\n",
    "1. `generate_data`\n",
    "2. `learn_model`\n",
    "3. `apply_model`\n",
    "\n",
    "### `generate_data`\n",
    "\n",
    "With the clean examples and the `blur` function, we have an unlimited amount of data for training and testing our classifier, an ANN that determines if a sensor image is hills, swamp, forest or plains.\n",
    "\n",
    "In classification, there is a general problem called the \"unbalanced class problem\". In general, we want our training data to have the same number of classes for each class. This means you should probably generate training data with, say, 100 of each type.\n",
    "\n",
    "But what do we do about the class label with the neural network?\n",
    "\n",
    "In this case, we can do \"one hot\". Instead of `generate_data` outputing a single 0 or 1, it should output a vector of 0's and 1's so that $y$ is now a vector as well as $x$. We can use the first position for hill, the second for swamp, the third for forest and the fourth for plains:\n",
    "\n",
    "```\n",
    "[0, 1, 0, 0]\n",
    "```\n",
    "\n",
    "what am I? swamp.\n",
    "\n",
    "Unlike logistic regression, you should set the *biases* inside the neural network (the implict $x_0$ = 1) because there are going to be lot of them (one for every hidden and output node).\n",
    "\n",
    "`generate_data` now only needs to take how many you want of each class:\n",
    "\n",
    "`generate_data( clean_data, 100)`\n",
    "\n",
    "generates 100 hills, 100 swamp, 100 forest, 100 plains and transforms $y$ into the respective \"one hot\" encoding. You can use the code from Module 12 as a starting point.\n",
    "\n",
    "### `learn_model`\n",
    "\n",
    "`learn_model` is the function that takes in training data and actually learns the ANN. If you're up to it, you can implement a vectorized version using Numpy but you might start with the loopy version first.\n",
    "\n",
    "*In the lecture, I mentioned that you usually should mean normalize your data but you don't need to do that in this case because the data is already on the range 0-1.*\n",
    "\n",
    "You should add a parameter to indicate how many nodes the hidden layer should have.\n",
    "\n",
    "When verbose is True, you should print out the error so you can see that it is getting smaller.\n",
    "\n",
    "When developing your algorithm, you need to watch the error so you'll set verbose=True to start. You should print it out every iteration and make sure it is declining. You'll have to experiment with both epsilon and alpha; and it doesn't hurt to make alpha adaptive (if the error increases, make alpha = alpha / 10).\n",
    "\n",
    "When you know that your algorithm is working, change your code so that the error is printed out only every 1,000 iterations (it takes a lot of iterations for this problem to converge, depending on your parameter values--start early).\n",
    "\n",
    "`learn_model` returns the neural network. The hidden layer will be one vector of thetas for each hidden node. And the output layer will have its own thetas, one for each output (4 in this case). Return it as a Tuple: (List of List, List of List).\n",
    "\n",
    "### `apply_model`\n",
    "\n",
    "`apply_model` takes the ANN (the model) and either labeled or unlabeled data. If the data is unlabeled, it will return predictions for each observation as a List of Tuples of the inferred value (0 or 1) and the actual probability (so something like (1, 0.73) or (0, 0.19) so you have [(0, 0.30), (1, 0.98), (0, 0.87), (0, 0.12)]. Note that unlike the logistic regression, the threshold for 1 is not 0.5 but which value is largest (0.98 in this case).\n",
    "\n",
    "If the data is labeled, you will return a List of List of Tuples of the actual value (0 or 1) and the predicted value (0 or 1). For a single data point, you'll have the pairs of actual values [(0, 1), (0, 0), (0, 0), (1, 0)] is a misclassification and [(0, 0), (0, 0), (1, 1), (0, 0)] will be a correct classification. Then you have a List of *those*, one for each observation.\n",
    "\n",
    "###  simple evaluation\n",
    "\n",
    "We have an \"unlimited\" supply of data so we'll just generate a training set and then a test set and see how well our neural network does. Use the error rate (correct classifications/total examples) for your evaluation metric. We'll learn about more sophisticated \n",
    "\n",
    "1. generate training set (how many do you think you need?)\n",
    "2. generate test set (how many is a good \"test\" of the network you built?)\n",
    "3. loop over [2, 4, 8] hidden nodes:\n",
    "    1. train model and apply to train data, calculate error rate.\n",
    "    2. apply to test data and calculate error rate.\n",
    "    3. print error rate\n",
    "    \n",
    "Which number of hidden nodes did best?\n",
    "\n",
    "**As always when working with Lists or Lists of Lists, be very careful when you are modifying these items in place that this is what you intend (you may want to make a copy first)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**calc_y_hat**<br>\n",
    "The `calc_y_hat` is a helper functionf for `forward_pass` and `apply_model`. GIven the data and theta it calculates the dot product of the data and theta. It passes the values int he activation function. It uses the following activation function\n",
    "$$ \\hat{y} = \\frac{1}{1+e^{-z}} $$\n",
    "\n",
    "Parameters:\n",
    "* **theta**: a `List of Lists` of theta values.\n",
    "* **data**: a `list of lists` of data we want to train the neural network with\n",
    "\n",
    "It returns,<br>\n",
    "updated `theta` values</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_y_hat(data, theta):\n",
    "    m_data = np.hstack((np.ones((len(data),1)), data))  # set Xo = 1\n",
    "    z = np.dot(theta, m_data.T).astype(float)\n",
    "    y_hat = 1/(1+np.exp(-z))\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**update_theta**<br>\n",
    "The `update_theta` is a helper functionf for `back_propogate`. It updates the thetas and the delta for that layer.\n",
    "\n",
    "Parameters:\n",
    "* **theta_in**: a `List of Lists` of current theta\n",
    "* **alpha** is the learning rate. It is set to 0.1 by default.\n",
    "* **y** `List` is the calculated y value for the layer for which we are updating theta\n",
    "* **delta** is the calculated error for the expected and actual y values.\n",
    "\n",
    "It returns,<br>\n",
    "updated `theta` values</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_theta(theta_in, y, delta, alpha = 0.1):\n",
    "    theta = deepcopy(theta_in)\n",
    "    for indx in range(y.shape[0]):\n",
    "        theta = theta + alpha * (np.multiply(np.array([y[indx]]).T, delta[indx])).T\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**forward_pass**<br>\n",
    "The `forward_pass` is a helper functionf for `learn_model`. It calculates the y values for the hidden and the output layers.\n",
    "\n",
    "Parameters:\n",
    "* **theta_in**: a `List of Lists` of current theta betwen input and hidden layer\n",
    "* **theta_out**: a `List of Lists` of current theta betwen output and hidden layer\n",
    "* **data**: a `list of lists` of data we want to train the neural network with\n",
    "\n",
    "It returns,<br>\n",
    "calculated `y` for hidden and output layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(data, theta_in, theta_out):\n",
    "    hidden_y = (calc_y_hat(data, theta_in)).T\n",
    "    out_y = (calc_y_hat(hidden_y, theta_out)).T\n",
    "    return hidden_y, out_y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**calculate_delta**<br>\n",
    "The `calculate_delta` is a helper functionf for `learn_model`. It calculated the error with \n",
    "actual and expected output ($\\delta_o$) and backpropagation error ($\\delta_h$).\n",
    "\n",
    "Parameters:\n",
    "* **hidden_l**: a `List of Lists` of calcualted y values though forward pass.\n",
    "* **out_l**: a `List of Lists` of calcualted y values though forward pass.\n",
    "* **theta_out**: a `List of Lists` of current theta betwen output and hidden layer\n",
    "* **data**: a `list of lists` of data we want to train the neural network with\n",
    "\n",
    "It returns,<br>\n",
    "calculated `𝛿𝑜` and `𝛿ℎ`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_delta(data, hidden_l, out_l, theta_out):\n",
    "    delta_o = np.multiply(np.multiply(out_l,(1-out_l)), np.array(data[:,-1].tolist()) - out_l)\n",
    "    hidden_l = np.hstack((np.ones((len(hidden_l),1)), hidden_l))\n",
    "    delta_h = np.multiply(np.multiply(hidden_l, (1-hidden_l)), np.dot(delta_o, theta_out))[:,1:]   # drop the leading 1 we added for bias term\n",
    "    return delta_o, delta_h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**calculate_delta**<br>\n",
    "The `back_propogate` is a helper functionf for `learn_model`. It calculated the error with \n",
    "actual and expected output ($\\delta_o$) and backpropagation error ($\\delta_h$).\n",
    "\n",
    "Parameters:\n",
    "* **hidden_l**: a `List of Lists` of calcualted y values though forward pass.\n",
    "* **out_l**: a `List of Lists` of calcualted y values though forward pass.\n",
    "* **theta_out**: a `List of Lists` of current theta betwen output and hidden layer\n",
    "* **data**: a `list of lists` of data we want to train the neural network with\n",
    "\n",
    "It returns,<br>\n",
    "calculated `𝛿𝑜` and `𝛿ℎ`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propogate(data, theta_in, theta_out, hidden_l, alpha, delta_o, delta_h):\n",
    "    theta_out = update_theta(theta_out, hidden_l, delta_o, alpha)\n",
    "    lead_1_data = np.hstack((np.ones((data.shape[0],1)), data[:,:-1]))   # add a Xo = 1 and remove label column\n",
    "    theta_in  = update_theta(theta_in, lead_1_data, delta_h, alpha)\n",
    "    return theta_in, theta_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**calculate_delta**<br>\n",
    "The `evaluate` calculates the accuracy of the model.\n",
    "\n",
    "Parameters:\n",
    "* **model**: a `tuple` of thetas between the layers.\n",
    "\n",
    "It returns<br>\n",
    "`error rate` of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    x = [1 for row in model if (1,1) not in row]\n",
    "    error_rate = sum(x) / len(model)\n",
    "    return error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Put your helper functions above here.\n",
    "\n",
    "## Main Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate_data\n",
    "\n",
    "Generates an endless supply of blurred data from a collection of terrain prototypes.\n",
    "\n",
    "* `data`: Dict[Str, List[Any]] - a Dictionary of \"clean\" prototypes for each landscape type.\n",
    "* `n`: Int - the number of blurred examples of each terrain type to return.\n",
    "\n",
    "returns\n",
    "\n",
    "* List[List[Any]] - a List of Lists. Each individual List is a blurred example of a terrain type, generated from the prototype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_data(data, n):\n",
    "    labels = set(clean_data.keys())\n",
    "    data = []\n",
    "    label_vec = {\"hills\": np.array([1,0,0,0], dtype = int),\n",
    "                 \"swamp\": np.array([0,1,0,0], dtype = int),\n",
    "                 \"forest\":np.array([0,0,1,0], dtype = int),\n",
    "                 \"plains\":np.array([0,0,0,1], dtype = int)}\n",
    "    \n",
    "    for label in labels:\n",
    "        for _ in range(n):\n",
    "            datum = blur(random.choice(clean_data[label]))\n",
    "            datum[-1] = label_vec[label]\n",
    "            data += [datum]\n",
    "    random.shuffle(data)\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### learn_model\n",
    "The `learn_modellearn_model` calculates the accuracy of the model.\n",
    "* **data**: a `list of lists` of data we want to train the neural network with\n",
    "* **hidden_node**: The number of nodes NN should have in the hidden layers.\n",
    "* **iterations**: The number of iterations we want the NN to train the mode.\n",
    "* **verbose**: It indicates if we want to print errors\n",
    "* **alpha** : It is the learning rate of the neural network. It is set to 0.01 by default.\n",
    "\n",
    "returns<br>\n",
    "`tuple` of trained thetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def learn_model( data, hidden_nodes, iterations= 5000, verbose=False, alpha = 0.01):\n",
    "    theta_in = np.random.rand(hidden_nodes, data.shape[1])\n",
    "    theta_out = np.random.rand(4, hidden_nodes+1)\n",
    "    count = 0\n",
    "    \n",
    "    for count in range(1, iterations):\n",
    "        hidden_l, out_l = forward_pass(data[:,:-1], theta_in, theta_out)\n",
    "        delta_o, delta_h = calculate_delta(data, hidden_l, out_l, theta_out)\n",
    "        hidden_l = np.hstack((np.ones((len(hidden_l),1)), hidden_l))    # add Xo = 1\n",
    "        theta_in, theta_out = back_propogate(data, theta_in, theta_out, hidden_l, alpha, delta_o, delta_h)\n",
    "        print(f\"iteration:{count}, Error:{abs(np.mean(delta_o) + np.mean(delta_h))}\")if verbose and count%1000== 0 else None\n",
    "    model = (theta_in, theta_out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply_model\n",
    "It uses the trained model to predict values for the test data.\n",
    "\n",
    "* **model**: a `tuple of thetas`.\n",
    "* **test_data**: `List of Lists` of data we want to test the model with.\n",
    "* **labeled**: It indicates if the test data has labels or not. By default it is set to False.\n",
    "\n",
    "returns<br>\n",
    "If the data is labeled, you will return a `List of List of Tuples` of the actual value (0 or 1) and the predicted value (0 or 1).If the data is labeled, you will return a List of List of Tuples of the actual value (0 or 1) and the predicted value (0 or 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_model( model, test_data, labeled=False):\n",
    "    probs = []\n",
    "    decode = {0:[1,0,0,0] , 1:[0,1,0,0], 2:[0,0,1,0] , 3:[0,0,0,1]}\n",
    "    theta_in, theta_out = model\n",
    "    if labeled:\n",
    "        hidden_l, out_l = forward_pass(test_data[:,:-1], theta_in, theta_out)\n",
    "        for indx in range(len(test_data)):\n",
    "            probs += [list(zip(np.array(test_data[indx,-1].tolist()), decode[np.argmax(out_l[indx])]))]\n",
    "    else:\n",
    "        hidden_l, out_l = forward_pass(test_data[:,:-1], theta_in, theta_out)\n",
    "        for indx in range(len(out_l)):\n",
    "            probs += [list(zip(decode[np.argmax(out_l[indx])],out_l[indx]))]\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test out generate_data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07611112174569426 0.1446667944285972 0.08350839546420175\n",
      " 0.13397158539096415 0.14620582341786756 0.1695493228818369\n",
      " 0.04754865848585447 0.109522349280596 0.7106934270686723\n",
      " 0.17515335556568581 0.8277675545041622 0.11626608923909311\n",
      " 0.9286683251370755 0.797099498310642 0.9275331505983125\n",
      " 0.8295782688451387 array([0, 1, 0, 0])]\n",
      "[0.0 0.043056806524432084 0.14617789461419817 0.09726291052748963\n",
      " 0.0398707642098864 0.13369533343775766 0.0 0.15747543702983446\n",
      " 0.10300302755337408 0.8662290972328955 0.152169538884254\n",
      " 0.8164071290076035 0.7698975269832377 1.0 0.9702127378505241\n",
      " 0.8705565670772331 array([0, 1, 0, 0])]\n",
      "[0.0 0.09377447439300667 0.054884631337114416 0.1622226268908221\n",
      " 0.02384232737910774 0.0656041951270808 0.14913442990558182\n",
      " 0.0689867638447237 0.05564258507249166 0.1967332060958121\n",
      " 0.10672231120021203 0.04000641984079026 0.9683120856425563\n",
      " 0.9888065817699689 1.0 0.8985649078144331 array([0, 0, 0, 1])]\n",
      "[0.07274030153880759 0.07766847032349047 0.11640198191505405\n",
      " 0.11598297211029134 0.1153758962125427 0.003882335045696156\n",
      " 0.7941878537379538 0.06705635113505126 0.13022921001203705\n",
      " 0.8322511270426791 0.8074984834847516 0.9028341682864021\n",
      " 0.9701525993248609 0.8511257089805812 0.761155985755431\n",
      " 0.9377804783847308 array([1, 0, 0, 0])]\n",
      "[1.0 0.1454226046295712 0.11889887289480604 0.062394130194847915\n",
      " 0.9054803709876469 0.8140264436520918 0.0958017755313914\n",
      " 0.11030510753202565 0.8797249444787264 0.7875909232911611\n",
      " 0.9446970070568574 0.1338190281180378 0.9693351248977178\n",
      " 0.12945919670331515 0.13636322475774476 0.1438609963276475\n",
      " array([0, 0, 1, 0])]\n",
      "[0.11834654061066568 0.04581695903296499 0.07497921845635862\n",
      " 0.08155873937782367 1.0 0.06312073763413797 0.13066125795094938\n",
      " 0.09962792748490136 1.0 0.8750072558355275 0.0 0.057763120457906124\n",
      " 0.7708899590195623 0.7901687237488879 1.0 0.13325340242336192\n",
      " array([1, 0, 0, 0])]\n",
      "[0.11153483728361815 0.12309730842425567 0.007323867051535288\n",
      " 0.14285809629423735 0.2480885901622945 0.1198086654312232\n",
      " 0.18242024804625584 0.1742094369772622 0.0807250698939744\n",
      " 0.08336299285361945 0.11844436280148656 0.04840652221114305 1.0\n",
      " 0.8441417067214981 0.8927832726009524 0.8802469150362923\n",
      " array([0, 0, 0, 1])]\n",
      "[0.0997106257973513 0.9162462327036064 0.06967234535889644\n",
      " 0.11991207636953075 0.9478750147845747 0.8758216513270894\n",
      " 0.7125686147555336 0.06165100664238497 0.8666338196671572\n",
      " 0.8249450205942033 0.9038812914927274 0.8509585682803723\n",
      " 0.06880453863152323 0.7770215359403366 0.17512547238517995\n",
      " 0.062353402909187707 array([0, 0, 1, 0])]\n",
      "[0.1255048728930351 0.9443945858803592 0.16784833731249527\n",
      " 0.14237594184290064 0.8852212053171582 0.9036942851921147\n",
      " 0.8794887589549766 0.18004773248469708 0.9304426941564685\n",
      " 0.8196944668371883 1.0 1.0 0.07127768971583863 0.7433380689002139\n",
      " 0.15969464221203927 0.19991162556215802 array([0, 0, 1, 0])]\n",
      "[0.16225127141523263 0.13182317036772861 0.7736873391588681\n",
      " 0.14291356528610788 0.08328999765441542 0.7753640271116194\n",
      " 0.9116114893757047 0.7776608853010091 1.0 0.7693761327559502\n",
      " 0.9583224094382844 0.8395833988961856 0.07303722947784433\n",
      " 0.08630607585156783 0.9795992627959853 0.09711457227130253\n",
      " array([0, 0, 1, 0])]\n",
      "[0.9165323327238524 0.011281806886671616 0.11479136967475133 0.0\n",
      " 0.927220858971261 0.9699530834131347 0.13634185812037308\n",
      " 0.026204620465715783 0.876250267664808 0.9506168557697376 1.0\n",
      " 0.10645222146395605 0.9434967004635257 0.053810310059358074\n",
      " 0.10479041638306524 0.10764746341818171 array([0, 0, 1, 0])]\n",
      "[0.04105222504304512 0.08700569325093231 0.12324765174328745\n",
      " 0.10341280534920644 0.16447430188425208 0.04878410663755361\n",
      " 0.16883168963753015 0.10801453851215548 1.0 0.08334445779545216\n",
      " 0.8653201787343141 0.07693408582201788 0.7815328331362367\n",
      " 0.9405585467723179 0.7954493210067035 1.0 array([0, 1, 0, 0])]\n",
      "[0.10214516464028844 0.12540742964660231 0.02862495913024375\n",
      " 0.09275583474550832 0.13647910300750415 0.019127763222819977\n",
      " 0.13373470634549958 0.14021935646226116 1.0 0.00017145630636469789\n",
      " 0.9578832528659162 0.10062247134326416 0.8945894223979288\n",
      " 0.8156394576883743 0.6991631907713824 0.7873406212088344\n",
      " array([0, 1, 0, 0])]\n",
      "[0.10994539254115088 0.14538785571379065 0.002004416474275017\n",
      " 0.15587482024988522 0.15183465945911526 0.7971890376138726\n",
      " 0.09477674524891375 0.038038983164784615 0.9312201524564603\n",
      " 0.8362947560600573 0.9232623749472192 0.08197018066754565\n",
      " 0.8691019548041289 0.796853208468151 1.0 0.9034146153520839\n",
      " array([1, 0, 0, 0])]\n",
      "[0.16754265660507392 0.1396793736425092 0.14601473743547552\n",
      " 0.08669919111134333 0.08651519519688661 0.17132255958817927\n",
      " 0.8410260952858366 0.22820150395501557 0.10656823698524338\n",
      " 0.807801558653636 0.702763824733471 0.956764201088513 0.9423709595447229\n",
      " 1.0 0.9101831693181484 0.7837899987149659 array([1, 0, 0, 0])]\n",
      "[0.15984467419349502 0.10509533032809988 0.07268328509738445\n",
      " 0.07430103877297584 0.06601969188845638 0.19305634629615404\n",
      " 0.1816618655565691 0.030409501978962722 0.13341061659181813\n",
      " 0.8484706191772676 0.17581192986258148 0.9009619521295127\n",
      " 0.996296708220627 0.74546042745037 0.7658932056424899 0.859027313596813\n",
      " array([0, 1, 0, 0])]\n",
      "[0.08301329142674554 0.05317107072474864 0.12207301889262792\n",
      " 0.06739471068489816 0.15826519249370752 0.13353284430037382\n",
      " 0.11012332093916827 0.9273935672353696 0.05722343555170287\n",
      " 0.12863935260040954 0.9265759280587947 1.0 0.09748539731390284\n",
      " 0.7204239825593006 1.0 1.0 array([1, 0, 0, 0])]\n",
      "[0.059177703832434134 0.07964077492299934 0.007571020010734841\n",
      " 0.02195681678454521 0.09100572141183985 0.1133402229408158\n",
      " 0.138750701511523 0.05535068065093409 0.11160263961694046\n",
      " 0.1551257216160567 0.15816049328646142 0.13979361459441955\n",
      " 0.9212257189059381 0.9012565225441654 0.8663177628422107\n",
      " 0.9528635957681747 array([0, 0, 0, 1])]\n",
      "[0.16991080604826703 0.07711994371222325 0.09962458342604691\n",
      " 0.008013462455559561 0.07382810754375489 0.09466734016142114\n",
      " 0.08011189027653218 0.05365492146596184 1.0 0.15568750173636464\n",
      " 0.8952287553879884 0.12997624029355045 0.9405575424122368\n",
      " 0.9983233695341217 0.9636516972384694 0.9197086348315677\n",
      " array([0, 1, 0, 0])]\n",
      "[0.14011275437055287 0.09583517200600361 0.0930363790097162\n",
      " 0.051101916499312276 0.1191542085344912 0.11276819374134008\n",
      " 0.1496606184376804 0.05251734969281285 0.096918158702307\n",
      " 0.157191163589823 0.12030242713152775 0.07999838364239423\n",
      " 0.8305869094004694 0.8321494368410526 0.9831716663727907\n",
      " 0.6065608664651663 array([0, 0, 0, 1])]\n",
      "[0.07782773058922325 0.22124733203677993 0.09206313473878097\n",
      " 0.14249916000323537 0.17208384451026648 0.9402670805803117 0.0\n",
      " 0.09197550290145456 0.8037611961260404 0.9352694420145902 1.0\n",
      " 0.12611643070008316 0.9368589695830501 0.9220112163744583\n",
      " 0.7489307324190811 0.9394736045669924 array([1, 0, 0, 0])]\n",
      "[0.10726796446583241 0.14471108975959357 0.1064126162305614\n",
      " 0.10949194840664352 0.047141208155282735 0.10466773485268702\n",
      " 0.07560745945331736 0.07717238761062736 0.06609227674748466\n",
      " 0.07293004144012497 0.07650563100320393 0.07050865328001944 1.0\n",
      " 0.8295770279146804 0.8169708301743818 0.960773491928824\n",
      " array([0, 0, 0, 1])]\n",
      "[0.07798957924174293 0.02552315917397059 0.12194282329396869\n",
      " 0.12181759146039368 0.17724756545372658 0.06052749953661258\n",
      " 0.9680053278228073 0.09431408733758659 0.1019078597070185\n",
      " 0.8336137440098198 0.8150299260443193 0.7284094546729138\n",
      " 0.9866161535543887 1.0 0.8088509569869087 1.0 array([1, 0, 0, 0])]\n",
      "[0.006757761968192055 0.07931617300684243 0.12692590426030928 0.0\n",
      " 0.1040925397781913 0.07642082365334772 0.026633427054548395\n",
      " 0.020691704116348214 0.13743564312057382 0.07060231435353868\n",
      " 0.08432684527981296 0.06657860124992912 0.9338536240099563 1.0 1.0\n",
      " 0.9210680573979669 array([0, 0, 0, 1])]\n",
      "[0.10410304626240194 0.09462751848045436 0.11649201760849262\n",
      " 0.15119029962479852 0.17685346405506677 0.13584143419113798\n",
      " 0.1613758214590094 0.0882219486628723 0.05990601702756907\n",
      " 0.10766208944475794 0.13728626895362359 0.1552633586693383 1.0\n",
      " 0.8633268822455014 0.8865144481250995 0.888965622629204\n",
      " array([0, 0, 0, 1])]\n",
      "[0.1278895641242759 0.10274296479892513 0.1423299836919225\n",
      " 0.003997470718178547 0.13977126508428195 0.16278138712145182\n",
      " 0.0165808991586244 0.1612030581213333 0.14575257814913245\n",
      " 0.09049719306191606 0.19388804659053305 0.034748237845997273 1.0\n",
      " 0.6839895147326374 0.7192725430303291 1.0 array([0, 0, 0, 1])]\n",
      "[0.138526287157857 0.13963634057345095 0.07084442283620186\n",
      " 0.8777377631926068 0.16940010757363172 0.16265257072457173\n",
      " 0.8996905033559428 0.9155419367020229 0.14398903267231816\n",
      " 0.8071953423609911 0.8577557024864808 0.9210241255055777\n",
      " 0.1303947901639506 0.12044980405028999 0.20841235211028636\n",
      " 0.7608087355201957 array([0, 0, 1, 0])]\n",
      "[0.03321883078399644 0.06871306415736614 0.09709984391205456\n",
      " 0.09300777525144653 0.06325770318138252 0.04519879317531594\n",
      " 0.1857744111771505 0.15041373979791445 0.1780206240335486\n",
      " 0.9722278175527937 0.037379871362972925 0.9920829397054878\n",
      " 0.9864308633391015 0.9722306622639474 0.8702614713134442\n",
      " 0.8848326107811969 array([0, 1, 0, 0])]\n",
      "[0.0805727990158239 0.10676814736249941 0.17553052761812898\n",
      " 0.07585676760966953 0.15021973738864317 0.07525207023951921\n",
      " 0.0794778009482496 0.11569984493452848 0.8679822972639946\n",
      " 0.05519135254673671 0.815191087022574 0.08563806324288842\n",
      " 0.9419385147846658 0.8882410822742948 0.731703362143966\n",
      " 0.9720164559597503 array([0, 1, 0, 0])]\n",
      "[0.0628351111624958 0.12910709766238665 0.7813296859155809\n",
      " 0.09311208288827486 0.16536358747144786 0.8989931384985232\n",
      " 0.8096743007820267 1.0 0.8106435500342157 1.0 0.8783186017373318\n",
      " 0.9071424213397677 0.03132411237083174 0.11608190867586995\n",
      " 0.9143618634991435 0.09573687023030279 array([0, 0, 1, 0])]\n",
      "[0.10943695438977583 0.1596013241709675 0.0488976547260098\n",
      " 0.04278820147085434 0.07267511082568164 0.12326485013620052\n",
      " 0.04715702118585929 0.06289581591287158 0.06789618008294546\n",
      " 0.1263537433452555 0.11925768860167862 0.13838481827297885\n",
      " 0.9605565419510818 0.9920270705154282 0.7490078280773369\n",
      " 0.8924381503299791 array([0, 0, 0, 1])]\n",
      "[0.03291906076272354 0.18143381038227815 0.08343772294061155\n",
      " 0.0971192780539384 0.1003972499973029 0.1261006901781546\n",
      " 0.14571290922044244 0.09615440411445803 0.05174472784682735\n",
      " 0.770923265787198 0.14161060268075026 0.8275726359232228\n",
      " 0.8660714625948226 0.9634065934776007 0.8847540347664767\n",
      " 0.8787844803762085 array([0, 1, 0, 0])]\n",
      "[0.06981130048250214 0.08034058001818689 0.07016074496369584\n",
      " 0.07819759692318039 0.10305624967316744 0.04040108570080925\n",
      " 0.14268683342676014 0.0 0.11295146956774413 0.8066257199875839\n",
      " 0.14784848058041772 0.9809820997620877 0.9071802973177128\n",
      " 0.848067250308066 1.0 0.850810390188939 array([0, 1, 0, 0])]\n",
      "[0.10099712922428476 0.015365917883460617 0.9742472601859389\n",
      " 0.16755312449533763 0.13913349193078575 1.0 0.8576117710493336\n",
      " 0.9646392344573794 1.0 0.856761470845656 0.9222738916890951 1.0\n",
      " 0.023621974195525877 0.07701205346375392 0.9729069003172858\n",
      " 0.18877556869049147 array([0, 0, 1, 0])]\n",
      "[0.12159173090564562 0.10839338363542649 0.12969019769576812\n",
      " 0.1255837225312475 0.16844980086928668 0.09461052573213687\n",
      " 0.10882750410489214 0.8619426865554013 0.15060804218136434\n",
      " 0.0887974343428418 0.8279302037154121 0.968982512466372\n",
      " 0.1490029152534721 0.9152693112701806 0.8609066101866666\n",
      " 0.7563877345371983 array([1, 0, 0, 0])]\n",
      "[0.07349419623132226 0.14697712156562662 0.19302790653664764\n",
      " 0.05492141759150709 0.8399312879758782 0.12457510109837075\n",
      " 0.04183258634808762 0.09566579239733305 0.8457128917012096\n",
      " 0.9070202888864362 0.04890185631989089 0.04715248044952722\n",
      " 0.8659606576346586 0.8081755634850816 1.0 0.17814595839135655\n",
      " array([1, 0, 0, 0])]\n",
      "[0.07736971672875581 0.27917355887870393 0.23660017422919905\n",
      " 0.1058398420723051 0.006543485816203787 0.08353442100112576\n",
      " 0.04492724996657002 0.060663476895502055 0.15328446063233328\n",
      " 0.12508205210496204 0.05383281918067047 0.15090323501879566\n",
      " 0.7404483137936638 0.9406517489358195 0.9729691973403897\n",
      " 0.9424628897700316 array([0, 0, 0, 1])]\n",
      "[0.05925667571682279 1.0 0.10638202334312434 0.04627130122611996\n",
      " 0.8615020032333641 0.9519056771030087 0.8124636896737752\n",
      " 0.1710615883414633 0.789390491461436 0.957988414227419 0.7564959548610376\n",
      " 0.8439717364512708 0.06424849323710016 0.8509889919427531\n",
      " 0.1127982378772076 0.03672586361658765 array([0, 0, 1, 0])]\n",
      "[0.8934340754834764 0.08566831392205654 0.13827964238247256\n",
      " 0.13700552102402624 0.8139769266896526 1.0 0.09493723064851181\n",
      " 0.08899485500433452 1.0 0.9078407642987444 0.9721370777507677\n",
      " 0.07021767534280188 0.822530627012811 0.12842902197317013\n",
      " 0.13422030040274857 0.0013783279221054323 array([0, 0, 1, 0])]\n",
      "[0.07571340133772576 0.09299043278611795 0.18619687988750236\n",
      " 0.09896618913749254 0.16851141164007755 0.9605053719772694\n",
      " 0.10738246922793032 0.06165153511857352 0.955926859121564\n",
      " 0.9610924638511958 0.85635866670952 0.10816563168032754 1.0\n",
      " 0.7555313833896459 0.8881830429414915 0.8794242595827781\n",
      " array([1, 0, 0, 0])]\n"
     ]
    }
   ],
   "source": [
    "results = generate_data( clean_data, 10)\n",
    "for result in results:\n",
    "    print( result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `generate_data` to generate 100 blurred examples of each type (all four terrains)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = generate_data( clean_data, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `learn_model` to learn a ANN model for classifying sensor images as hills, swamps, plains or forest. **Set Verbose to True**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:1000, Error:1.997144140979119e-05\n",
      "iteration:2000, Error:7.515215177033066e-06\n",
      "iteration:3000, Error:4.520140324484738e-06\n",
      "iteration:4000, Error:3.2029892132552155e-06\n"
     ]
    }
   ],
   "source": [
    "model = learn_model(train_data, 8, iterations = 4001, verbose = True, alpha = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `generate_data` to generate 100 blurred examples of each terrain and use this as your test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = generate_data( clean_data, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the model and evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = apply_model( model, test_data, labeled=True)\n",
    "evaluate(results)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print( results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you're pretty sure your algorithm works (the error rate during training is going down, and you can evaluate `apply_model` results for its error rate), you need to determine what the best number of hidden nodes is.\n",
    "\n",
    "Try 2, 4, or 8 hidden nodes and indicate the best one. Follow the outline above under \"Simple Evaluation\".\n",
    "In the \"real world\", you could 10 fold cross validation and validation curves to determine the number of hidden nodes and possibly if you needed one or two hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Nodes:2, error_rate:0.0%\n",
      "Hidden Nodes:4, error_rate:0.0%\n",
      "Hidden Nodes:8, error_rate:0.0%\n"
     ]
    }
   ],
   "source": [
    "hidden_nodes = [2,4,8]\n",
    "train = generate_data( clean_data, 300) \n",
    "test = generate_data( clean_data, 300) \n",
    "\n",
    "for h_nodes in hidden_nodes:\n",
    "    t_model = learn_model(train, h_nodes, iterations=4501, alpha=0.01)\n",
    "    t_result = apply_model(t_model, test, labeled=True)\n",
    "    error_rate = evaluate(t_result)\n",
    "    print(f\"Hidden Nodes:{h_nodes}, error_rate:{error_rate*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which number of hidden nodes is best? __8__<br>\n",
    "I found that there was one best node number that gave the best result considering only the accuracy as it can be seen above. I think the best result out the 3 option would be 8 hidden nodes in the hidden layer. I think that because more hidden nodes help make a higher order decision boundry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before You Submit...\n",
    "\n",
    "1. Did you provide output exactly as requested?\n",
    "2. Did you re-execute the entire notebook? (\"Restart Kernel and Rull All Cells...\")\n",
    "3. If you did not complete the assignment or had difficulty please explain what gave you the most difficulty in the Markdown cell below.\n",
    "4. Did you change the name of the file to `jhed_id.ipynb`?\n",
    "\n",
    "Do not submit any other files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (en605645)",
   "language": "python",
   "name": "en605645"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "207px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
