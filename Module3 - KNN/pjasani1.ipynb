{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Module 3 - Programming Assignment\n",
    "\n",
    "## Directions\n",
    "\n",
    "1. Change the name of this file to be your JHED id as in `jsmith299.ipynb`. Because sure you use your JHED ID (it's made out of your name and not your student id which is just letters and numbers).\n",
    "2. Make sure the notebook you submit is cleanly and fully executed. I do not grade unexecuted notebooks.\n",
    "3. Submit your notebook back in Blackboard where you downloaded this file.\n",
    "\n",
    "*Provide the output **exactly** as requested*\n",
    "\n",
    "<div style=\"background: lemonchiffon; margin:20px; padding: 20px;\">\n",
    "    <strong>Note</strong>\n",
    "    <p>\n",
    "This assignment is a lot more structured than others to keep you on the rails.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## k Nearest Neighbors and Model Evaluation\n",
    "\n",
    "In this programming assignment you will use k Nearest Neighbors (kNN) to build a \"model\" that will estimate the compressive strength of various types of concrete. This assignment has several objectives:\n",
    "\n",
    "1. implement the kNN algorithm. Remember...the data + distance function is the model in kNN.\n",
    "2. evaluate a machine learning algorithm. Because this is a *regression* problem, we will use Mean Squared Error:\n",
    "\n",
    "$$MSE = \\frac{1}{n}\\sum^n_i (y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "3. use validation curves to tune a *hyperparameter* of the model. In this case, the hyperparameter is *k*, the number of neighbors.\n",
    "\n",
    "4. evaluate the *generalization error* of the model.\n",
    "\n",
    "5. use learning curves to determine if getting more data will improve our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "The function `parse_data` loads the data from the specified file and returns a List of Lists. The outer List is the data set and each element (List) is a specific observation. Each value of an observation is for a particular measurement. This is what we mean by \"tidy\" data.\n",
    "\n",
    "The function also returns the *shuffled* data because the data might have been collected in a particular order that *might* bias training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import List, Dict, Tuple, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(file_name: str) -> List[List]:\n",
    "    data = []\n",
    "    file = open(file_name, \"r\")\n",
    "    for line in file:\n",
    "        datum = [float(value) for value in line.rstrip().split(\",\")]\n",
    "        data.append(datum)\n",
    "    random.shuffle(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = parse_data(\"concrete_compressive_strength.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[286.3, 200.9, 0.0, 144.7, 11.2, 1004.6, 803.7, 56.0, 72.99]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1030"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 1,030 observations and each observation has 8 measurements. The data dictionary for this data set tells us the definitions of the individual variables (columns/indices):\n",
    "\n",
    "| Index | Variable | Definition |\n",
    "|-------|----------|------------|\n",
    "| 0     | cement   | kg in a cubic meter mixture |\n",
    "| 1     | slag     | kg in a cubic meter mixture |\n",
    "| 2     | ash      | kg in a cubic meter mixture |\n",
    "| 3     | water    | kg in a cubic meter mixture |\n",
    "| 4     | superplasticizer | kg in a cubic meter mixture |\n",
    "| 5     | coarse aggregate | kg in a cubic meter mixture |\n",
    "| 6     | fine aggregate | kg in a cubic meter mixture |\n",
    "| 7     | age | days |\n",
    "| 8     | concrete compressive strength | MPa |\n",
    "\n",
    "The target (\"y\") variable is a Index 8, concrete compressive strength in (Mega?) [Pascals](https://en.wikipedia.org/wiki/Pascal_(unit))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Splits - n folds\n",
    "\n",
    "With n fold cross validation, we divide our data set into n subgroups called \"folds\" and then use those folds for training and testing. You pick n based on the size of your data set. If you have a small data set--100 observations--and you used n=10, each fold would only have 10 observations. That's probably too small. You want at least 30. At the other extreme, we generally don't use n > 10.\n",
    "\n",
    "With 1,030 observations, n = 10 is fine so we will have 10 folds.\n",
    "`create_folds` will take a list (xs) and split it into `n` equal folds with each fold containing one-tenth of the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folds(xs: List, n: int) -> List[List[List]]:\n",
    "    k, m = divmod(len(xs), n)\n",
    "    # be careful of generators...\n",
    "    return list(xs[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = create_folds(data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We always use one of the n folds as a test set (and, sometimes, one of the folds as a *pruning* set but not for kNN), and the remaining folds as a training set.\n",
    "We need a function that'll take our n folds and return the train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(folds: List[List[List]], index: int) -> Tuple[List[List], List[List]]:\n",
    "    training = []\n",
    "    test = []\n",
    "    for i, fold in enumerate(folds):\n",
    "        if i == index:\n",
    "            test = fold\n",
    "        else:\n",
    "            training = training + fold\n",
    "    return training, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the function to give us a train and test datasets where the test set is the fold at index 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = create_train_test(folds, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "927"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## kNN\n",
    "\n",
    "kNN is a bit weird because it's a \"lazy\" algorithm...it uses the data set (training data) as the model. \n",
    "\"Eager\" algorithms, in constrast, build some kind of generalization of the training data and then throw the training data away.\n",
    "The basic algorithm is:\n",
    "\n",
    "```\n",
    "    1. use the train data as a database\n",
    "    2. take an observation as a query\n",
    "    3. calculate the distance between the query and every observation in the database\n",
    "    4. collect the k nearest observations\n",
    "    5. if this is classification, return the majority class label of the target.\n",
    "    6. if this is regression, return the average value of the target.\n",
    "```\n",
    "\n",
    "In the real world, there are data structures that make this \"find the nearest k\" more efficient but we don't need that for 1,000 points.\n",
    "We also don't need to handle *both* the classification and the regression versions. Let's just handle regression.\n",
    "\n",
    "Although kNN doesn't result in a model, we can use a higher order function to create a kNN regressor. The interior function will \"close over\" (a closure) the formal parameter (database) of build_knn. The order of the parameters allows us to vary the k or create a partially applied function where k is fixed:\n",
    "\n",
    "\n",
    "```\n",
    "knn = build_knn(train)\n",
    "knn3 = partial(knn, 3)\n",
    "result = knn3(query)\n",
    "\n",
    "# or\n",
    "\n",
    "result = knn(3, query)\n",
    "\n",
    "```\n",
    "\n",
    "It all depends on the context.\n",
    "\n",
    "For this problem, use **Euclidean distance**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_knn(database):\n",
    "    def knn(k, query, debug = False):\n",
    "        euc_distance = []\n",
    "        \n",
    "        # calculate euclidean distance\n",
    "        for obs in database:\n",
    "            euc_distance += [(sum([(query[i] - obs[i])**2 for i in range(len(query)-1)])**0.5, obs[-1])]\n",
    "            \n",
    "        euc_distance.sort(key = lambda obs: obs[0])\n",
    "        \n",
    "        if debug == True:\n",
    "            print(\"Query:\", query)\n",
    "            for i in range(len(euc_distance[:k])):\n",
    "                print(f\"\\t Nearest observation {i}: y = {euc_distance[i][-1]}\") \n",
    "            print(f\"Predicted y = {round(sum([obs[1] for obs in euc_distance[:k]])/k, 4)}\")\n",
    "            print(\"\\n\")\n",
    "            \n",
    "        return round(sum([obs[1] for obs in euc_distance[:k]])/k, 4)\n",
    "    return knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** This is might be your first exposure to a function that creates and returns a function. `database` is a formal parameter of `build_knn` and when you use it in the function body of `knn`, `knn` \"closes over\" the parameter. Hence, `knn` is a closure.\n",
    "\n",
    "The saying goes that \"closures are a poor person's object and an object is a poor person's closure.\" Closures are a very common practice in functional programming.\n",
    "\n",
    "**Note** \"database\" is just what we call the observations (data set) used in our knn model. During evaluation, it's the training data set. When we're done, it would be the full data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build kNN\n",
    "\n",
    "Using Fold 1 as a test set, create train and test sets from our folds. Then build a kNN \"model\" (function) with k=10. Using the first three members of the test set, calculate predicted concrete compressive strength for them.\n",
    "\n",
    "**Note** Remember that Lists are 0-indexed so Fold 1 is at index 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted concrete compressive strength [48.759, 24.244, 30.139]\n"
     ]
    }
   ],
   "source": [
    "train, test = create_train_test(folds, 0)\n",
    "knn = build_knn(train)\n",
    "result = [knn(10, test[i]) for i in range(3)]\n",
    "print(\"Predicted concrete compressive strength\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generalization Error\n",
    "\n",
    "Continuing with k = 10, let's see what our *generalization* error might be.\n",
    "Although we call it \"generalization error\", it's not necessarily error but will be the evaluation metric that we've picked.\n",
    "Generalization error is the error (metric) we expect to see when we use our model on unseen data.\n",
    "We can calculate this estimate using all 10 folds and rotating through them, using each as the test set.\n",
    "\n",
    "1. divide data into folds\n",
    "2. for each fold,\n",
    "3. use that fold as the test set and the remaining folds as the train set.\n",
    "4. build a model using the train set.\n",
    "5. calculate the model's evaluation metric on the test set.\n",
    "6. calculate the average and standard deviation for the metric and estimate the confidence interval.\n",
    "\n",
    "But how can we tell if our model is any good?\n",
    "One way is that you may have some required or optimal value of the evaluation metric in mind.\n",
    "For example, a classification algorithm might require 97% accuracy or better.\n",
    "\n",
    "You can also use a *baseline* model.\n",
    "We often use \"null\" models as a baseline.\n",
    "For regression, that's the mean of the target variable (y).\n",
    "They're called \"null\" models because they don't use any features to predict the target...they're based on just the target value itself.\n",
    "(You'd be surprised how many times a null model is good enough for decision making).\n",
    "\n",
    "If you're using the mean as your model, what does \"build a model\" entail?\n",
    "Calculate the mean of y from the training set.\n",
    "\"Calculate the evaluation metric on the test set\" entails using the mean as a *constant* prediction for each value of the test set and calculating the evaluation metric (MSE).\n",
    "\n",
    "So you're going to calculate confidence intervals for *two* models: kNN with k = 3 and the null model (the mean).\n",
    "Again, the mean of a value is a perfectly legitimate model of the data.\n",
    "\n",
    "**Note** The mean as a baseline or null model is *not* the same as MSE the evaluation metric. You will have two sets of evaluation metrics, one for the baseline model and one for the kNN model.\n",
    "\n",
    "The confidence interval function is provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean_confidence interval\n",
    "\n",
    "This function calculates the mean of *data* and the confidence bounds of that mean.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "* **data** a List of floating point numbers representing the data.\n",
    "* **confidence** a scalar (float) indicating the desired confidence bounds. The default is 95% (0.95).\n",
    "\n",
    "**returns** the mean and a Tuple of the (low, high) values of the *confidence*% bounds. For example, 23.8 (21.2, 26.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_confidence_interval(data: List[float], confidence: float=0.95) -> Tuple[float, Tuple[float, float]]:\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, (m-h, m+h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we need is a function that takes the real values of y and the predicted values of y and calculates the evaluation metric. In our case, that's MSE:\n",
    "\n",
    "\n",
    "$$MSE = \\frac{1}{n}\\sum^n_i (y_i - \\hat{y}_i)^2$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_metric(actual: List, predicted: List) -> float:\n",
    "    assert(len(actual) == len(predicted))\n",
    "    eval_mse = sum([(actual[i] - predicted[i])**2 for i in range(len(actual))])/len(actual)\n",
    "    return eval_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the generalization error for your kNN and the null model. You will print out 2 confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Std of knn metric 21.036493859243667\n",
      "mean of  knn metric 74.4461237323107\n",
      "KNN Confidence Interval: (58.58350531142905, 90.30874215319234)\n",
      "\n",
      "\n",
      "Std of null metric 40.652901371651026\n",
      "mean of  null metric 279.6118455824952\n",
      "NULL Confidence Interval: (248.95742824113407, 310.26626292385635)\n"
     ]
    }
   ],
   "source": [
    "knn_metrics = []\n",
    "null_metrics = []\n",
    "for i in range(0, len(folds)):\n",
    "    train, test = create_train_test(folds, i)\n",
    "    knn = build_knn(train)                                                        # build model\n",
    "    predicted_y = [knn(3, test[i]) for i in range(len(test))]                     # predict_y for test-set \n",
    "    actual_y = [obs[-1] for obs in test]                                          # get actual y for test-set\n",
    "    knn_metrics += [evaluation_metric(actual_y, predicted_y)]                     # eval metrix for KNN\n",
    "    mean_train_y = sum([obs[-1] for obs in train]) / len(train)                   # calculate the mean of y from train-set\n",
    "    null_metrics += [evaluation_metric(actual_y, [mean_train_y]*len(actual_y))]   # evaluate metric for null\n",
    "    \n",
    "mean_knn, ci_knn = mean_confidence_interval(knn_metrics)\n",
    "mean_null, ci_null = mean_confidence_interval(null_metrics)\n",
    "knn_std = np.std(knn_metrics)\n",
    "print(f\"Std of knn metric {knn_std}\")\n",
    "print(f\"mean of  knn metric {mean_knn}\")\n",
    "print(f\"KNN Confidence Interval: {ci_knn}\")\n",
    "print(\"\\n\")\n",
    "print(f\"Std of null metric {np.std(null_metrics)}\")\n",
    "print(f\"mean of  null metric {mean_null}\")\n",
    "print(f\"NULL Confidence Interval: {ci_null}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is your kNN model better than the null model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the above result I can say that the KNN model is much better then null model. As we can see above the standard deviation for knn_metrics is much lower then standard deviation for null_metrics.\n",
    "We can also observe that the confidence interval for knn_metrics is tighter then confidence interval for null_metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setting Hyperparameters\n",
    "\n",
    "Now let's see if we can find a better k for our problem, concrete compressive strength.\n",
    "We can do this using *validation* curves.\n",
    "Validation curves require a few things:\n",
    "\n",
    "1. pick an evaluation metric (problem dependent)\n",
    "2. create train and test sets\n",
    "3. for each proposed value of the hyperparameter:\n",
    "4. build a model using the train set and the value\n",
    "5. calculate the evaluation metric using the model against the train set (itself).\n",
    "6. calculate the evaluation metric using the model against the *test* set.\n",
    "7. plot the resulting *two* curves.\n",
    "8. see if they suggest anything\n",
    "\n",
    "Theoretically, it shouldn't matter which fold you use for your test set for this step.\n",
    "In practice, you can often get different results and you should average them but we're not going to do that here.\n",
    "\n",
    "For kNN, this is all a bit confusing because *normally* \"build a model\" requires the current, proposed value of the hyperparameter you're tuning...but in kNN, we use the hyperparameter *afterwards*. For example, for Decision Trees, the hyperparameter might be \"maximum tree depth\" and you need to know that value each time you build a new model with the train set.\n",
    "\n",
    "But \"build a model\" here is just \"chuck all the data into a function\". ¯\\\\_(ツ)_/¯\n",
    "\n",
    "The only practical difference this makes is that \"build a model\" is going to go *outside* the loop going over each hyperparamter value instead of inside."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to do the looping over potential values of k. For *classification*, we prefer odd values of k so that there's always a majority. For regression, we don't care. Let's look at k=[1, 20]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = list(range(1, 21))\n",
    "test_mse = []\n",
    "train_mse = []\n",
    "train, test = create_train_test(folds, 0)                                   # choose the train and test set\n",
    "for k in ks:                                                                # for each proposed value of hyperparameter\n",
    "    knn = build_knn(train)                                                  # build model using trains et\n",
    "    predicted_train = [knn(k, obs) for obs in train]                        # predict y for train set\n",
    "    predicted_test = [knn(k, obs) for obs in test]                          # predcit y for test set\n",
    "    actual_train_y = [obs[-1] for obs in train]                             # get actual_y for train-set\n",
    "    actual_test_y = [obs[-1] for obs in test]                               # get actual_y for test-set\n",
    "    test_mse += [evaluation_metric(actual_test_y, predicted_test)]          # eval metric for test-set\n",
    "    train_mse += [evaluation_metric(actual_train_y, predicted_train)]       # eval metric for train-set itself\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the curves to *hopefully* see if there's a clearly better value for k...one that doesn't overfit or underfit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ks, train_mse, 'r', ks, test_mse, 'b')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Average MSE')\n",
    "plt.legend([\"train\", \"test\"])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your interpretation of the validation curves, what is the best value of k?\n",
    "Remember, it's not necessarily the lowest value but the lowest value with certain characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the above plot I can say that k=8 would give the best result which is shown by a sudden decrese in average MSE followed by sudden increase. The plot above shows low testing error rate at chosen k which mean we have best performance at that k value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background: lemonchiffon; margin:20px; padding: 20px;\">\n",
    "    <strong>Note</strong>\n",
    "    <p>Normally, you would then revisit the generalization error analysis to see if you've made a real improvement.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose your own adventure\n",
    "\n",
    "You have three options for the next part:\n",
    "\n",
    "1. You can implement mean normalization (also called \"z-score standardization\") of the *features*; do not normalize the target, y. See if this improves the generalization error of your model (middle).\n",
    "\n",
    "2. You can implement *learning curves* to see if more data would likely improve your model (easiest).\n",
    "\n",
    "3. You can implement *weighted* kNN and use the real valued GA to choose the weights. weighted kNN assigns a weight to each item in the Euclidean distance calculation. For two points, j and k:\n",
    "$$\\sqrt{\\sum w_i (x^k_i - x^j_i)^2}$$\n",
    "\n",
    "You can think of normal Euclidean distance as the case where $w_i = 1$ for all features  (ambitious, but fun...you need to start EARLY because it takes a really long time to run).\n",
    "\n",
    "The easier the adventure the more correct it must be..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**standardize**\n",
    "\n",
    "The `standardize` takes the original data and applies Z-score standardization. It uses the below function to calcualte the z-score.\n",
    "$$\\frac{1}{N}\\sum_{x=1}^n \\frac{(x-\\mu}{\\sigma}$$\n",
    "\n",
    "Parameters:\n",
    "* **dataset** is the data we want to apply standardization on.\n",
    "\n",
    "retuns:<br>\n",
    "it returns the standardized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(dataset):\n",
    "    features_means, features_std  = [], []\n",
    "    standardized_dataset = [[] for _ in range(len(dataset))]\n",
    "    \n",
    "    for col in range(len(dataset[0])-1):\n",
    "        features_means += [sum([obs[col] for obs in dataset])/ len(dataset)]                                # calc mean for each features\n",
    "        features_std += [(sum([(obs[col]-features_means[col])**2 for obs in dataset])/ len(dataset))**0.5]  # calc standard deviation for each feature \n",
    "                                              \n",
    "    for row_num in range(len(dataset)):                                               # Standardize the data\n",
    "        for col in range(len(dataset[0])-1):\n",
    "            standardized_dataset[row_num] += [(dataset[row_num][col]-features_means[col])/features_std[col]]\n",
    "            if col == (len(dataset[0])-2):                                            # add the target column\n",
    "                standardized_dataset[row_num] += [dataset[row_num][-1]]\n",
    "\n",
    "    return standardized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Z-score standardiztion\n",
      "Std of knn metric: 21.036493859243667\n",
      "mean of  knn metric: 74.4461237323107\n",
      "KNN Confidence Interval: (58.58350531142905, 90.30874215319234)\n",
      "\n",
      "\n",
      "After Z-score standardiztion\n",
      "Std of knn metric: 17.54325334190329\n",
      "mean of  knn metric: 73.52829073427185\n",
      "KNN Confidence Interval: (60.29975866588306, 86.75682280266064)\n"
     ]
    }
   ],
   "source": [
    "# apply standardization and \n",
    "stnd_data = standardize(data)\n",
    "folds = create_folds(stnd_data, 10)\n",
    "knn_metrics = []\n",
    "\n",
    "for i in range(0, len(folds)):\n",
    "    train, test = create_train_test(folds, i)\n",
    "    knn = build_knn(train)                                                        # build model\n",
    "    predicted_y = [knn(3, test[i]) for i in range(len(test))]                     # predict_y for test-set \n",
    "    actual_y = [obs[-1] for obs in test]                                          # get actual y for test-set\n",
    "    knn_metrics += [evaluation_metric(actual_y, predicted_y)]                     # eval metrix for KNN\n",
    "    \n",
    "mean_knn_stnd, ci_knn_stnd = mean_confidence_interval(knn_metrics)\n",
    "knn_stnd_std = np.std(knn_metrics)\n",
    "\n",
    "print(\"Before Z-score standardiztion\")\n",
    "print(f\"Std of knn metric: {knn_std}\")\n",
    "print(f\"mean of  knn metric: {mean_knn}\")\n",
    "print(f\"KNN Confidence Interval: {ci_knn}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"After Z-score standardiztion\")\n",
    "print(f\"Std of knn metric: {knn_stnd_std}\")\n",
    "print(f\"mean of  knn metric: {mean_knn_stnd}\")\n",
    "print(f\"KNN Confidence Interval: {ci_knn_stnd}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the above result to compare the generalizaiton error before and after the z-score standardization. We can observe that after applying Z-score standardization we have a tighter confidence interval and lower standard deviation which tells us that our model has slightly improved. We can also look at the plot below for more verification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# learning plot\n",
    "ks = list(range(1, 21))\n",
    "test_mse = []\n",
    "train_mse = []\n",
    "train, test = create_train_test(folds, 0)                                   # choose the train and test set\n",
    "for k in ks:                                                                # for each proposed value of hyperparameter\n",
    "    knn = build_knn(train)                                                  # build model using trains et\n",
    "    predicted_train = [knn(k, obs) for obs in train]                        # predict y for train set\n",
    "    predicted_test = [knn(k, obs) for obs in test]                          # predcit y for test set\n",
    "    actual_train_y = [obs[-1] for obs in train]                             # get actual_y for train-set\n",
    "    actual_test_y = [obs[-1] for obs in test]                               # get actual_y for test-set\n",
    "    test_mse += [evaluation_metric(actual_test_y, predicted_test)]          # eval metric for test-set\n",
    "    train_mse += [evaluation_metric(actual_train_y, predicted_train)]       # eval metric for train-set itself\n",
    "\n",
    "# plot\n",
    "plt.plot(ks, train_mse, 'r', ks, test_mse, 'b')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Average MSE')\n",
    "plt.legend([\"train\", \"test\"])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Before You Submit...\n",
    "\n",
    "1. Did you provide output exactly as requested?\n",
    "2. Did you re-execute the entire notebook? (\"Restart Kernel and Rull All Cells...\")\n",
    "3. If you did not complete the assignment or had difficulty please explain what gave you the most difficulty in the Markdown cell below.\n",
    "4. Did you change the name of the file to `jhed_id.ipynb`?\n",
    "\n",
    "Do not submit any other files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (en605645)",
   "language": "python",
   "name": "en605645"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "117px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
