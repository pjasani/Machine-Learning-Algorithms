{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 12 - Programming Assignment\n",
    "\n",
    "## Directions\n",
    "\n",
    "1. Change the name of this file to be your JHED id as in `jsmith299.ipynb`. Because sure you use your JHED ID (it's made out of your name and not your student id which is just letters and numbers).\n",
    "2. Make sure the notebook you submit is cleanly and fully executed. I do not grade unexecuted notebooks.\n",
    "3. Submit your notebook back in Blackboard where you downloaded this file.\n",
    "\n",
    "*Provide the output **exactly** as requested*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Problem\n",
    "\n",
    "When we last left our agent in Modules 1 and 11, it was wandering around a world filled with plains, forests, swamps, hills and mountains. This presupposes a map with known terrain:\n",
    "\n",
    "```\n",
    "......\n",
    "...**.\n",
    "...***\n",
    "..^...\n",
    "..~^..\n",
    "```\n",
    "\n",
    "but what if all we know is that we have some area of interest, that we've reduced to a GPS grid:\n",
    "\n",
    "```\n",
    "??????\n",
    "??????\n",
    "??????\n",
    "??????\n",
    "??????\n",
    "```\n",
    "\n",
    "and the agent has to determine what kind of terrain is to the left, front and right of it?\n",
    "\n",
    "Assuming the agent has a very simple visual sensor that constructs a 4x4 grayscale image for each of the three directions, it might it could see something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "plain =  [0.0, 0.0, 0.0, 0.0,0.0, 0.0, 0.0, 0.0,0.0, 0.0, 0.0, 0.0,1.0, 1.0, 1.0, 1.0]\n",
    "forest = [0.0, 1.0, 0.0, 0.0,1.0, 1.0, 1.0, 0.0,1.0, 1.0, 1.0, 1.0,0.0, 1.0, 0.0, 0.0]\n",
    "hills =  [0.0, 0.0, 0.0, 0.0,0.0, 0.0, 1.0, 0.0,0.0, 1.0, 1.0, 1.0,1.0, 1.0, 1.0, 1.0]\n",
    "swamp =  [0.0, 0.0, 0.0, 0.0,0.0, 0.0, 0.0, 0.0,1.0, 0.0, 1.0, 0.0,1.0, 1.0, 1.0, 1.0]\n",
    "\n",
    "figure = plt.figure(figsize=(20,6))\n",
    "\n",
    "axes = figure.add_subplot(1, 3, 1)\n",
    "pixels = np.array([255 - p * 255 for p in plain], dtype='uint8')\n",
    "pixels = pixels.reshape((4, 4))\n",
    "axes.set_title( \"Left Camera\")\n",
    "axes.imshow(pixels, cmap='gray')\n",
    "\n",
    "axes = figure.add_subplot(1, 3, 2)\n",
    "pixels = np.array([255 - p * 255 for p in forest], dtype='uint8')\n",
    "pixels = pixels.reshape((4, 4))\n",
    "axes.set_title( \"Front Camera\")\n",
    "axes.imshow(pixels, cmap='gray')\n",
    "\n",
    "axes = figure.add_subplot(1, 3, 3)\n",
    "pixels = np.array([255 - p * 255 for p in hills], dtype='uint8')\n",
    "pixels = pixels.reshape((4, 4))\n",
    "axes.set_title( \"Right Camera\")\n",
    "axes.imshow(pixels, cmap='gray')\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which would be plains, forest and hills respectively.\n",
    "\n",
    "## The Assignment\n",
    "\n",
    "For this programming assignment your tasks are:\n",
    "\n",
    "1. Write a logistic regression that simply determines if something is a hill or not (two class problem). \n",
    "2. You will also evaluate that logistic regression by generating a *confusion matrix*.\n",
    "\n",
    "For a starting point, refer to the Pseudocode and the Self-Check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We have clean examples of the different types of terrain but based on the location, the registration can be a bit off for some of the types and the visual sensor is often noisy.\n",
    "\n",
    "Here are the clean examples with different registrations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = {\n",
    "    \"plains\": [\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, \"plains\"]\n",
    "    ],\n",
    "    \"forest\": [\n",
    "        [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, \"forest\"],\n",
    "        [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, \"forest\"],\n",
    "        [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, \"forest\"],\n",
    "        [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, \"forest\"]\n",
    "    ],\n",
    "    \"hills\": [\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, \"hills\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, \"hills\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, \"hills\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, \"hills\"]\n",
    "    ],\n",
    "    \"swamp\": [\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, \"swamp\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, \"swamp\"]        \n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function that allows us to view any of these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_sensor_image( data):\n",
    "    figure = plt.figure(figsize=(4,4))\n",
    "    axes = figure.add_subplot(1, 1, 1)\n",
    "    pixels = np.array([255 - p * 255 for p in data[:-1]], dtype='uint8')\n",
    "    pixels = pixels.reshape((4, 4))\n",
    "    axes.set_title( \"Left Camera:\" + data[-1])\n",
    "    axes.imshow(pixels, cmap='gray')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"I think that I shall never see a thing so lovely as a tree.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_sensor_image( clean_data[ \"forest\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_sensor_image( clean_data[\"swamp\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that comes in, however, is noisy. The values are never exactly 0 and 1. In order to mimic this we need a `blur` function.\n",
    "\n",
    "We will assume that noise is normally distributed. For values that should be 0, the noisy values are distributed $N(0.10, 0.05)$. For values should be 1, the noisy values are distributed $N(0.9, 0.10)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur( data):\n",
    "    def apply_noise( value):\n",
    "        if value < 0.5:\n",
    "            v = random.gauss( 0.10, 0.05)\n",
    "            if v < 0.0:\n",
    "                return 0.0\n",
    "            if v > 0.75:\n",
    "                return 0.75\n",
    "            return v\n",
    "        else:\n",
    "            v = random.gauss( 0.90, 0.10)\n",
    "            if v < 0.25:\n",
    "                return 0.25\n",
    "            if v > 1.00:\n",
    "                return 1.00\n",
    "            return v\n",
    "    noisy_readings = [apply_noise( v) for v in data[0:-1]]\n",
    "    return noisy_readings + [data[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how this affects what the agent *actually* sees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_sensor_image( blur( clean_data[\"swamp\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "We need four (4) functions:\n",
    "\n",
    "1. `generate_data`\n",
    "2. `learn_model`\n",
    "3. `apply_model`\n",
    "4. `evaluate`\n",
    "\n",
    "### generate_data\n",
    "\n",
    "`generate_data` has been written for you.\n",
    "\n",
    "* clean_data - the clean versions of the \"bitmaps\" for each of the terrain types\n",
    "* n - the number of samples for \"in the class\" (1) and \"not in the class\" (0) to generate.\n",
    "* label - the label to chose as \"in the class\".\n",
    "\n",
    "For example,\n",
    "\n",
    "`generate_data( clean_data, 100, \"hills\")`\n",
    "\n",
    "generates 100 hills, 100 not hills and has transformed the String labels into 1 and 0, respectively.\n",
    "\n",
    "### `learn_model`\n",
    "\n",
    "`learn_model` is the function that takes in training data and actually learns the logistic regression model. If you're up to it, you can implement a vectorized version using Numpy but you might start with the loopy version first.\n",
    "\n",
    "*In the lecture, I mentioned that you usually should mean normalize your data but you don't need to do that in this case because the data is already on the range 0-1.*\n",
    "\n",
    "I should also mention that gradient descent is not the usual approach to linear regression because the error function actually has an *exact* solution. However, in the case of large data sets, the exact solution often fails and in any case, the use of gradient descent will prepare you for neural networks next week.\n",
    "\n",
    "When verbose is True, you should print out the error so you can see that it is getting smaller. \n",
    "\n",
    "When developing your algorithm, you need to watch the error so you'll set verbose=True to start. You should print it out every iteration and make sure it is declining. You'll have to experiment with both epsilon and alpha; and it doesn't hurt to make alpha adaptive (if the error increases, make alpha = alpha / 10).\n",
    "\n",
    "When you know that your algorithm is working, change your code so that the error is printed out only every 1,000 iterations (it takes a lot of iterations for this problem to converge, depending on your parameter values--start early).\n",
    "\n",
    "`learn_model` returns the List of Thetas.\n",
    "\n",
    "### `apply_model`\n",
    "\n",
    "`apply_model` takes a List of Thetas (the model) and either labeled or unlabeled data. If the data is unlabeled, it will return predictions for each observation as a Tuple of the inferred value (0 or 1) and the actual probability (so something like (1, 0.73) or (0, 0.59). We always return the class with the higher probability.\n",
    "\n",
    "If the data are labeled, you will return a Tuple of the actual value (0 or 1) and the predicted value (0 or 1). In this case, you return a List of something like [(0, 1), (1, 1), (0, 0), (1, 0)].\n",
    "\n",
    "### `evaluate`\n",
    "\n",
    "Ideally, we should be running 10 fold cross validation on this problem but...that might take a while so we're going to just go ahead with a simple evaluation. We're interested not only in the error rate but the overall \"confusion\" of the model.\n",
    "\n",
    "The `evaluate` takes the results of `apply_model` when labeled=True and prints out the error rate and a confusion matrix.\n",
    "\n",
    "---\n",
    "\n",
    "Why `labeled=True` or `labeled=False`? While we only have labeled data right now, for model evaluation. In the future, you would need to use this function to do actual classification. In that case, `labeled=False`. Because in the long run, that's the default usage, we use `False` as the default.\n",
    "\n",
    "---\n",
    "\n",
    "**As always when working with Lists or Lists of Lists, be very careful when you are modifying these items in place that this is what you want.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "Put your helper functions above here.\n",
    "\n",
    "## Main Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `generate_data` to generate a balanced set of blurred \"hills\" and \"not-hills\" examples to test that the function is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0.06172513423234574, 0.23592363672926486, 0.12160553147573022, 0.19317886892462155, 0.967565087152456, 0.08659199305270643, 0.09642522795544894, 0.08294936014530511, 0.7355009516444457, 0.9111257323240597, 0.0863852236807589, 0.08214225600946364, 0.7372611227544699, 0.7167224163052397, 0.835843702000627, 0.10422959343031629], 1)\n",
      "([0.0, 0.13952818632463204, 0.05606190841172322, 0.0012395693653946827, 0.10094381688852185, 0.1684713193243697, 0.008156788949058191, 0.053561564925015605, 0.13049027120979592, 0.007179056544905332, 0.21540345508809033, 0.08108834146051894, 0.8442220717768266, 0.9100409149532686, 0.9217186811398204, 0.7698358371403431], 0)\n",
      "([0.02054211627031008, 0.2113859287429954, 0.11782099523340335, 0.0851950484583473, 0.07427047064984815, 0.8513864715038224, 0.09349589126142505, 0.16998507268173685, 0.8021529096748768, 0.8600568893404645, 0.7649732789843637, 0.14391594159766943, 0.8893308699285951, 0.7913063403507509, 1.0, 0.8209922963032474], 1)\n",
      "([0.09403168469146614, 0.06024913714631906, 0.15485459141499852, 0.0, 1.0, 0.0841150371485871, 0.09855314411093265, 0.15848609641861214, 0.870378170317756, 0.8711569399184893, 0.11932084616218985, 0.06272416439415547, 1.0, 0.810213923351295, 0.84073475421922, 0.1937912626029667], 1)\n",
      "([0.15451647100339375, 0.12927664456068402, 0.11128696391585985, 0.16328686202888995, 0.15989849136802342, 0.15968026078259723, 0.07575711888251577, 0.806649914563564, 0.01804683007630023, 0.11687201541353573, 0.8312451679460927, 0.9610781467957937, 0.08743799628605665, 0.97742408128853, 1.0, 0.7962745902796348], 1)\n",
      "([0.08819759483712264, 0.14397833968413074, 0.0598429873777572, 0.9221351269539763, 0.07008077255965897, 0.1692184842197528, 0.9815429742260858, 0.8707222425355124, 0.03537394244805128, 0.9581213459490967, 0.9244537895363676, 0.7580535684667584, 0.1454789173908867, 0.03899192282984285, 0.018884163170882345, 0.8783277493150293], 0)\n",
      "([0.13163932335791503, 0.11746104790113826, 0.13999347856298075, 0.053617581655608405, 0.04503391014055922, 0.8517589429503909, 0.07796420732480008, 0.09028831004046343, 0.8856631685113243, 0.9793726769621804, 0.9078876526205606, 0.14120715135862144, 0.8037549723088998, 1.0, 1.0, 0.9333265920439863], 1)\n",
      "([0.10937991394007619, 0.07531309893028763, 0.020406551403097092, 0.08134333036448338, 0.6611834810474784, 0.07573007198611235, 0.10491432943371388, 0.09893929684017293, 0.7756766612499928, 0.8118218663310846, 0.10073350683062879, 0.10071373990047988, 0.8446745884841588, 0.9899910370093182, 0.7518442378064596, 0.1289925184163253], 1)\n",
      "([0.03356065785316191, 0.05100514340261287, 0.16836907134938361, 0.16664316239252464, 0.1473272446239015, 0.05213940929743474, 0.11644881394368657, 0.11531858351879064, 0.9223576829376428, 0.08235396756727355, 0.8414570015959733, 0.13720798536161133, 0.8688777800060645, 0.8467462904220976, 0.8021230984874533, 0.7860909538900276], 0)\n",
      "([0.029605115930130238, 0.09644885634874449, 0.07915345211740955, 0.12228434463575716, 0.03994353650263852, 0.19373945197910222, 0.0, 0.08631705790170134, 0.06144283923404989, 0.0, 0.11770550132512289, 0.087243751978391, 0.8088000037001515, 1.0, 0.8786619019628541, 0.8256448261479061], 0)\n",
      "([0.08328791695410787, 0.09506631668966528, 0.07573089865141287, 0.020709966542757488, 0.0690170292861086, 0.06835554297822255, 1.0, 0.17564292873954346, 0.16132991806847663, 0.9099121774699572, 0.8437473160861798, 0.904845029259636, 0.8470281132353603, 0.9058136543774874, 0.8678396308332034, 1.0], 1)\n",
      "([0.042487515414927936, 0.03226557999707462, 0.21502394500791686, 0.9617932383523532, 0.029385626642923837, 0.08368105372406089, 0.8805775420055021, 1.0, 0.07207822892011614, 1.0, 0.8478572102827563, 0.8432416527895871, 0.04115121555307188, 0.11255995399776436, 0.1332862880288941, 0.9694973532920615], 0)\n",
      "([0.8858428742764813, 0.06251297818054269, 0.07938633710041565, 0.04097141945533365, 0.8030652957287528, 0.8534181774170293, 0.04480779737941533, 0.008797894717298013, 0.8878785018134986, 0.8668066685702894, 0.667077199613495, 0.11980492410355573, 0.8074826586998567, 0.0971567616496006, 0.0380851373783224, 0.1102229179726943], 0)\n",
      "([0.14853098599371792, 0.06249580345646839, 0.2003211529542081, 0.13673227397633558, 0.13690338537076369, 0.17903821586007454, 0.10601592587105228, 0.19430900736484405, 0.9093694537379429, 0.11849483581707791, 0.7231740163995379, 0.09501354335080449, 0.8927000256017636, 0.8324561670333499, 0.9121811270421645, 0.9581871601239709], 0)\n",
      "([0.025235634972995122, 0.17708086256891534, 0.15768425079633225, 0.1450743042831522, 0.11863353250060259, 0.869329736081128, 0.11545097429222215, 0.032610470219197205, 0.8816117814131096, 0.794576809458585, 1.0, 0.17399969642383709, 0.9284797867478344, 0.9535509256774678, 0.9353785318202836, 0.9543351085656941], 1)\n",
      "([0.06530823309930578, 0.22707018051966288, 0.18545292365781998, 0.0748369842625384, 0.08423911974761303, 0.07231667678227671, 0.1321358140727018, 0.1489475068360237, 0.07237536434524199, 0.8804250745084602, 0.0653688833626668, 0.7700643434973511, 0.6583706932746407, 0.9230386058251537, 0.9863310054870891, 0.9257608486786276], 0)\n",
      "([0.10989812512158191, 0.09226066260162731, 0.13433323429594612, 0.11624740150037126, 0.04712536966987135, 0.8957058780791063, 0.12171790971209778, 0.12258710211146642, 0.8372584806115948, 1.0, 0.7534858482617621, 0.07717125484033965, 0.8228484914358762, 0.8427036040175772, 0.8332110821455952, 0.845890016673522], 1)\n",
      "([0.08937205897915138, 0.08921139331528889, 0.1354146672574386, 0.04855383634713605, 0.1974572995906684, 0.7870556084255099, 0.04898246866458891, 0.075086614588113, 0.8248521664348214, 0.9460953575775805, 0.8105273608096525, 0.1149616043475481, 0.9892788222358755, 0.9519755810875282, 0.8214706816083954, 0.7710615649776631], 1)\n",
      "([0.05634976123363717, 0.05962914598890618, 0.07684988724539898, 0.08066958379855846, 0.2071350133425485, 0.09335244686974567, 0.10736648266195642, 0.1036539228153037, 0.1586246979069761, 0.0, 0.1451524916682721, 0.015072304883673865, 1.0, 0.8907674467517587, 0.8615838933138381, 0.9339423888219979], 0)\n"
     ]
    }
   ],
   "source": [
    "def generate_data( data, n, key_label):\n",
    "    labels = set(clean_data.keys())\n",
    "    labels.remove(key_label)\n",
    "\n",
    "    total_per_label = int(n/len(labels))\n",
    "    data = []\n",
    "    # create n \"not label\" and code as y=0\n",
    "    for label in labels:\n",
    "        for _ in range(total_per_label):\n",
    "            datum = blur(random.choice(clean_data[label]))\n",
    "            xs = datum[0:-1]\n",
    "            data.append((xs, 0))\n",
    "    # create n \"label\" and code as y=1\n",
    "    for _ in range(n):\n",
    "        datum = blur(random.choice(clean_data[key_label]))\n",
    "        xs = datum[0:-1]\n",
    "        data.append((xs, 1))\n",
    "    random.shuffle(data)\n",
    "    return data\n",
    "\n",
    "results = generate_data( clean_data, 10, \"hills\")\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**calc_y_hat**<br>\n",
    "The `calc_y_hat` is a helper functionf for `learn_model`. It calculates the $\\hat{y}$t given the data and the thetas. It uses the below function to calculate the $\\hat{y}$.\n",
    "\n",
    "$$ \\hat{y} = \\frac{1}{1+e^{-\\theta_0}} $$\n",
    "\n",
    "Parameters:\n",
    "* **data**: a `List` of `List`s contaning the data we need to calculate $\\hat{y}$\n",
    "* **theta** is the `list` of float values we needed to calculate  $\\hat{y}$\n",
    "\n",
    "\n",
    "The function returns `List` of calculated  $\\hat{y}$ values</br>\n",
    "For example if data and theta are as shown below.\n",
    "```\n",
    "data = [[1.8, 0], [2.7, 1.0]]\n",
    "theta = [0.8, 1.1]\n",
    "```\n",
    "retuns:<br>\n",
    "`[0.94158544, 0.97746736]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_y_hat(data, theta):\n",
    "    m_data = np.hstack((np.ones((len(data),1)), data))  # set Xo = 1\n",
    "    z = theta.dot(m_data[:,:-1].T)\n",
    "    y_hat = 1/(1+np.exp(-z)) # reverse theta and pass in everyhthing but last y column\n",
    "    y_hat = np.ravel(y_hat)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**calc_error**<br>\n",
    "The `calc_error` is a helper functionf for `learn_model`. It calculates the error using the loss function given the data and the thetas. It uses the below function to calculate the $error$.\n",
    "\n",
    "$$ J(\\theta) = - \\frac{1}{n}\\sum_i y_i log(\\hat{y_i}) + (1 - y_i)log(1 - \\hat{y_i} ) $$\n",
    "\n",
    "Parameters:\n",
    "* **data**: a `List` of `List`s contaning the float values}\n",
    "* **theta** is the `list` of float values\n",
    "\n",
    "\n",
    "The function returns calculated `float` value.</br>\n",
    "For example if data and theta are as shown below.\n",
    "```\n",
    "data = [[1.8, 0], [2.7, 1.0]]\n",
    "theta = [0.8, 1.1]\n",
    "```\n",
    "retuns:<br>\n",
    "`0.46871918071283825`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_error(data, theta):\n",
    "    y_hat = calc_y_hat(data,theta)\n",
    "    ones = np.ones(len(data))\n",
    "    loss = -np.mean(data[:,-1] * np.log(y_hat) + (ones - data[:,-1]) * np.log(ones - y_hat))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**derivitive**<br>\n",
    "The `derivitive` is a helper functionf for `learn_model`. It calculates the derivitive to update the theta values while learning the model. It uses the below function to calculat the derivitive\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial \\theta_j} = \\frac{1}{n}\\sum_i(\\hat{y_i} - y_i)x_{ij} $$\n",
    "\n",
    "Parameters:\n",
    "* **data**: a `List` of `List`s contaning the float values\n",
    "* **theta** is the `list` of float values\n",
    "* **t_indx** keeps track of which theta we are currently calculating the derivitive of. theta_0 would make t_index=0.\n",
    "\n",
    "\n",
    "The function returns calculated `float` value.</br>\n",
    "For example if data, t_indx and theta are as shown below.\n",
    "```\n",
    "data = [[1.8, 0], [2.7, 1.0]]\n",
    "theta = [0.8, 1.1]\n",
    "t_indx = 0\n",
    "```\n",
    "retuns:<br>\n",
    "`0.8429655191367142`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivitive(data, theta, t_indx):\n",
    "    y_hat = calc_y_hat(data, theta)\n",
    "    ones = np.ones((len(data),1))\n",
    "    m_data = np.hstack((ones, data))  # set Xo = 1\n",
    "    der = (y_hat - data[:, -1]) * m_data[:, t_indx]\n",
    "    der = np.mean(der)\n",
    "    return der"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**learn_model**<br>\n",
    "The `learn_model` function implements the logistics regression algorithm. It calculates thetas that will reduce the error rate. The algorithm adapts the alpha value as required.\n",
    "\n",
    "\n",
    "Parameters:\n",
    "* **orig_data**: a `List` of `List`s contaning the float values\n",
    "* **verbose** is `boolean` variable that indicates if want to print error_rates or not. it is set to `False` by default.\n",
    "* **epsilon** is the value used to decide when to stop running the algorithm. It is set to `1e-07` by default.\n",
    "* **alpha** is the learning rate for the logistic regression algorithm. It is set to `0.1` by default.\n",
    "\n",
    "\n",
    "The function returns a `List` of theta values that give the smallest error.</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def learn_model( orig_data, verbose=False, epsilon = 1e-06, alpha = 0.1):                              \n",
    "    labels = np.array(list(zip(*orig_data))[1]).reshape((len(orig_data),1))   # seperate label\n",
    "    data = np.hstack((list(zip(*orig_data))[0], labels))                      # combine data and label as matrix\n",
    "    theta = np.random.uniform(-1, 1, len(data[0]))                            # genrate thetas (-1, 1)\n",
    "    p_error, t = 0.0, 0\n",
    "    c_error = calc_error(data, theta)\n",
    "    while abs(c_error-p_error) > epsilon:\n",
    "        # print(\"Error\", c_error) if verbose and t %1000 ==0 else None\n",
    "        if t %1000 == 0 and verbose == True:\n",
    "            print(\"Error for iteration \" + str(t) + \"=\", c_error)  \n",
    "        new_theta = np.zeros(len(theta))\n",
    "        for t_indx in range(len(theta)):\n",
    "            new_theta[t_indx] = theta[t_indx] - alpha * derivitive(data, theta, t_indx) \n",
    "        theta = new_theta\n",
    "        p_error = c_error\n",
    "        c_error = calc_error(data, theta)\n",
    "        alpha = alpha/10 if c_error > p_error else alpha   # update alpha is current erro > previous error\n",
    "        t += 1\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**predict**<br>\n",
    "The `predict` is a helper function for `apply_model`. Given the trained theta values and the test point it calculates the probability of datapoint.\n",
    "\n",
    "\n",
    "Parameters:\n",
    "* **model**: a `List` of float values.\n",
    "* **test** is the testpoint we want to predict a probability for.\n",
    "\n",
    "\n",
    "The function returns a `probability` for the given testpoint.</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test):\n",
    "    test = np.array(test).reshape((len(test), 1))\n",
    "    test = np.vstack((np.ones((1,1)), test))\n",
    "    z = model.dot(test)\n",
    "    prob = 1/(1+np.exp(-z))\n",
    "    return prob[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**apply_model**<br>\n",
    "The`apply_model` function calculate the probility for each of the testpoint in the test_data. If the test points are labeled then it created a list of (actual_label, predicted_label). If the given testpoint is unlabeled then it creates a list tuples of format (predicted label, predicted probability).\n",
    "\n",
    "\n",
    "Parameters:\n",
    "* **model**: a `List` of float values.\n",
    "* **test_data** is `List` of testpoints we want to predict a probability for.\n",
    "* **labeled** indicates whether the testpoints are labeled or not.\n",
    "\n",
    "\n",
    "The function returns a ` List of probabilities (tuples)` for the given test_data.</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model( model, test_data, labeled=False):\n",
    "    if labeled:   # we have labeled data\n",
    "        pred = [(test[1], round(predict(model, test[0]), 0)) for test in test_data]\n",
    "    else:                             # we do not have labeled data\n",
    "        pred = []\n",
    "        for test in test_data:\n",
    "            test_pred = predict(model, test)\n",
    "            pred += [(round(test_pred, 0), test_pred)]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**print_confusion_matrix**<br>\n",
    "The`print_confusion_matrix` function prints the confusion matrix given the dictionary contaning TP, TN, FP, FN. It prins the confusion matrix.\n",
    "\n",
    "\n",
    "Parameters:\n",
    "* **dct**: a `Dict` containing number of TP, TN, FP, FN.\n",
    "\n",
    "\n",
    "The function prints the confusion matrix in the below format.\n",
    "```\n",
    "Confusion Matrix\n",
    "         _______________________\n",
    "        |        Predicted     |\n",
    "________|_______ 1 __|___ 0 ___|\n",
    "    A   |   |        |         |\n",
    "    c   | 1 |    TP  |    FN   |\n",
    "    t   |___|________|_________|\n",
    "    u   |   |        |         |\n",
    "    a   | 0 |   FP   |   TN    |\n",
    "    l   |___|________|_________|\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_confusion_matrix(dct):\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(\"         \"+\"_\"*23)\n",
    "    print(\"        \"+\"|        Predicted     |\")\n",
    "    print(\"________\"+\"|_______ {} __|___ {} ___|\".format(1,0))\n",
    "    print(\"    A   |   |        |         |\")\n",
    "    print(\"    c   | {} |    {}  |    {}    |\".format(1, dct[(1,1)], dct[(1,0)]))\n",
    "    print(\"    t   |___|________|_________|\")\n",
    "    print(\"    u   |   |        |         |\")\n",
    "    print(\"    a   | {} |    {}   |   {}    |\".format(0, dct[(0,1)], dct[(0,0)]))\n",
    "    print(\"    l   |___|________|_________|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(results):\n",
    "    dct = {(0,0):0, (0,1):0, (1,0):0, (1,1):0}\n",
    "    for tp in results:\n",
    "        dct[tp] += 1\n",
    "    error_rate = (dct[(0,1)] + dct[(1,0)]) / len(results)\n",
    "    print(f\"Error rate: {round(error_rate*100, 3)}%\")\n",
    "   \n",
    "    print_confusion_matrix(dct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `generate_data` to generate 100 blurred \"hills\" examples balanced with 100 \"non hills\" examples and use this as your test data. Set labeled=True. Print out the first 10 results, one per line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = generate_data(clean_data, 100, \"hills\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = generate_data(clean_data, 100, \"hills\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `learn_model` to learn a logistic regression model for classifying sensor images as \"hills\" or \"not hills\". Use your `generate_data` function to generate a training set of size 100 for \"hills\". **Set Verbose to True**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for iteration 0= 1.0918476399402506\n",
      "Error for iteration 1000= 0.36689559151443146\n",
      "Error for iteration 2000= 0.25742855653286983\n",
      "Error for iteration 3000= 0.20524920531499788\n",
      "Error for iteration 4000= 0.1736995076782965\n",
      "Error for iteration 5000= 0.15216778450813553\n",
      "Error for iteration 6000= 0.13633982115763046\n",
      "Error for iteration 7000= 0.12410480062638582\n",
      "Error for iteration 8000= 0.11429834423176569\n",
      "Error for iteration 9000= 0.10622108183575943\n",
      "Error for iteration 10000= 0.09942524100192268\n",
      "Error for iteration 11000= 0.09360950407433695\n",
      "Error for iteration 12000= 0.0885628539790736\n",
      "Error for iteration 13000= 0.08413260348105288\n",
      "Error for iteration 14000= 0.08020522042830855\n",
      "Error for iteration 15000= 0.07669431907115075\n",
      "Error for iteration 16000= 0.07353285933841895\n",
      "Error for iteration 17000= 0.0706679184414895\n",
      "Error for iteration 18000= 0.068057090269914\n",
      "Error for iteration 19000= 0.06566594630684587\n",
      "Error for iteration 20000= 0.0634662072942173\n",
      "Error for iteration 21000= 0.06143440202743997\n",
      "Error for iteration 22000= 0.05955086703414412\n",
      "Error for iteration 23000= 0.05779898928811651\n",
      "Error for iteration 24000= 0.05616462513485596\n",
      "Error for iteration 25000= 0.05463564893995073\n",
      "Error for iteration 26000= 0.05320159856962526\n",
      "Error for iteration 27000= 0.05185339407364215\n",
      "Error for iteration 28000= 0.050583112353853724\n",
      "Error for iteration 29000= 0.04938380511127424\n",
      "Error for iteration 30000= 0.04824935058060222\n",
      "Error for iteration 31000= 0.047174331884739615\n"
     ]
    }
   ],
   "source": [
    "model = learn_model( train_data, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the model to the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = apply_model( model, test_data, labeled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the results above, print out your error rate (as a percent) and the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate: 0.503%\n",
      "Confusion Matrix\n",
      "         _______________________\n",
      "        |        Predicted     |\n",
      "________|_______ 1 __|___ 0 ___|\n",
      "    A   |   |        |         |\n",
      "    c   | 1 |    99  |    1    |\n",
      "    t   |___|________|_________|\n",
      "    u   |   |        |         |\n",
      "    a   | 0 |    0   |   99    |\n",
      "    l   |___|________|_________|\n"
     ]
    }
   ],
   "source": [
    "evaluate(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before You Submit...\n",
    "\n",
    "1. Did you provide output exactly as requested?\n",
    "2. Did you re-execute the entire notebook? (\"Restart Kernel and Rull All Cells...\")\n",
    "3. If you did not complete the assignment or had difficulty please explain what gave you the most difficulty in the Markdown cell below.\n",
    "4. Did you change the name of the file to `jhed_id.ipynb`?\n",
    "\n",
    "Do not submit any other files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def learn_model( data, hidden_nodes, iterations= 10000, verbose=False, alpha = 0.01):\n",
    "#     theta_in = np.random.rand(hidden_nodes, data.shape[1])\n",
    "#     theta_out = np.random.rand(4, hidden_nodes+1)\n",
    "#     # theta_in = np.array([[0.01, 0.26, -.42],[-0.05, 0.78, 0.19],[0.42, -.23, .37]])\n",
    "#     # theta_out = np.array([[0.2, 0.61, 0.12, -0.9],[0.3, 0.28, -0.34, 0.10]])\n",
    "#     count = 0\n",
    "#     model_list = []\n",
    "    \n",
    "#     while count != iterations:\n",
    "#         print(count) if verbose and count%1000== 0 else None\n",
    "#         hidden_l = calc_y_hat(data[:,:-1], theta_in).T     # hidden layer\n",
    "#         out_l = calc_y_hat(hidden_l, theta_out).T # output layer\n",
    "#         delta_o = np.multiply(np.multiply(out_l,(1-out_l)), np.array(data[:,-1].tolist()) - out_l)\n",
    "#         hidden_l = np.hstack((np.ones((len(hidden_l),1)), hidden_l))\n",
    "#         delta_h = np.multiply(np.multiply(hidden_l, (1-hidden_l)), np.dot(delta_o, theta_out))[:,1:]   # drop the leading 1 we added for bias term\n",
    "#         theta_out = update_theta(theta_out, alpha, hidden_l, delta_o)\n",
    "#         lead_1_data = np.hstack((np.ones((data.shape[0],1)), data[:,:-1]))   # add a leading 1 and remove label column\n",
    "#         theta_in  = update_theta(theta_in, alpha, lead_1_data, delta_h)\n",
    "#         # print(theta_in,\"\\n\",  theta_out)\n",
    "#         # print(\"\\n\")\n",
    "#         if count%100 ==0:\n",
    "#             model_list += [(theta_in, theta_out, count)]\n",
    "#         count += 1\n",
    "#     model = (theta_in, theta_out)\n",
    "#     model_list += [(theta_in, theta_out, count)]\n",
    "#     return model\n",
    "\n",
    "# # inpt = np.array([[0.52, -0.97, [1,0]]])\n",
    "# # theta_in = np.array([[0.01, 0.26, -.42],[-0.05, 0.78, 0.19],[0.42, -.23, .37]])\n",
    "# # theta_out = np.array([[0.2, 0.61, 0.12, -0.9],[0.3, 0.28, -0.34, 0.10]])\n",
    "# # learn_model(inpt, 3, 1)\n",
    "# # x = learn_model(results[:10], 8, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (en605645)",
   "language": "python",
   "name": "en605645"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "207px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
