{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 8 - Programming Assignment\n",
    "\n",
    "## Directions\n",
    "\n",
    "1. Change the name of this file to be your JHED id as in `jsmith299.ipynb`. Because sure you use your JHED ID (it's made out of your name and not your student id which is just letters and numbers).\n",
    "2. Make sure the notebook you submit is cleanly and fully executed. I do not grade unexecuted notebooks.\n",
    "3. Submit your notebook back in Blackboard where you downloaded this file.\n",
    "\n",
    "*Provide the output **exactly** as requested*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from math import log2\n",
    "import random\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "For this assignment you will be implementing and evaluating a Decision Tree using the ID3 Algorithm (**no** pruning or normalized information gain). Use the provided pseudocode. The data is located at (copy link):\n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/Mushroom\n",
    "\n",
    "**Just in case** the UCI repository is down, which happens from time to time, I have included the data and name files on Blackboard.\n",
    "\n",
    "One of the things we did not talk about in the lectures was how to deal with missing values. In C4.5, missing values were handled by treating \"?\" as an implicit attribute value for every feature. For example, if the attribute was \"size\" then the domain would be [\"small\", \"medium\", \"large\", \"?\"]. Another approach is to skip instances with missing values. Yet another approach is to infer the missing value conditioned on the class. For example, if the class is \"safe\" and the color is missing, then we would infer the attribute value that is most often associated with \"safe\", perhaps \"red\". **Use the \"?\" approach for this assignment.**\n",
    "\n",
    "\n",
    "\n",
    "You must implement the following functions:\n",
    "\n",
    "`cross_validate` takes the data and performs 10 fold cross validation (from Module 3!).\n",
    "\n",
    "`train` takes training_data and returns the Decision Tree as a data structure or object (a tree is definitely an Abstract Data Type, ADT, so OOP is warranted). Make sure your Tree can be represented somehow.\n",
    "\n",
    "`classify` takes a tree produced from the function above and applies it to labeled data (like the test set) or unlabeled data (like some new data).\n",
    "\n",
    "`evaluate` takes a data set with labels (like the training set or test set) and the classification result and calculates the classification error rate:\n",
    "\n",
    "$$error\\_rate=\\frac{errors}{n}$$\n",
    "\n",
    "Format your error rate so that it appears as a percent. That is, not 0.0234 but 2.34%.\n",
    "\n",
    "\n",
    "```\n",
    "def train(training_data):\n",
    "   # returns a decision tree data structure\n",
    "```\n",
    "\n",
    "and `classify` takes a tree and a List of instances (possibly just one) and returns the classifications:\n",
    "\n",
    "```\n",
    "def classify( tree, test_data):\n",
    "    # returns a list of classifications\n",
    "```\n",
    "\n",
    "and `evaluate` takes the actual classifications and the predicted classes and returns the classification error rate:\n",
    "\n",
    "```\n",
    "def evaluate(actual, predicted):\n",
    "    # returns an error rate\n",
    "```\n",
    "\n",
    "You must apply 10 fold cross validation to your data set. You will treat each fold as a test set, using the combined remainder as the training set. You should print out the error rate for each fold and then an average error rate for the entire cross validation process.\n",
    "\n",
    "This is all that is required for this assignment. I'm leaving more of the particulars up to you but you can definitely use the last module as a guide.\n",
    "\n",
    "**Note** Because this assignment has a natural recursive implementation, you should consider using `deepcopy` at the appropriate places.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**load_file**<br>\n",
    "The `load_file` load the file given the filename.\n",
    "\n",
    "Parameters:\n",
    "* **file_name** is the name of the file we want to load.\n",
    "\n",
    "retuns:<br>\n",
    "It return the data loaded form the file in `list of lists` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(file_name):\n",
    "    data = []\n",
    "    file = open(file_name, \"r\")\n",
    "    for line in file:\n",
    "        tmp_data = line.rstrip().split(\",\")\n",
    "        data += [tmp_data[1:] + tmp_data[:1]] # made sure the class column was the last one\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**get_attribute_metadata**<br>\n",
    "The `get_attribute_metadata` is a helper function for `train`. It creates a dictionary of all the attributes and its domain values.\n",
    "\n",
    "Parameters:\n",
    "* **data** is the data for which we want to get the attributes and its domains.\n",
    "\n",
    "retuns:<br>\n",
    "It return the `dictionary` of attributes and its domain values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attribute_metadata(data):\n",
    "    attributes = {}\n",
    "    for col_num in range(len(data[0])-1):\n",
    "        attributes[col_num] = list(set([row[col_num] for row in data]))\n",
    "    return attributes    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**entropy**<br>\n",
    "The `entropy` is a helper function for `id3 algorithm`. it calculates the entorpy of the given data. The below function is used to calculte the entropy.\n",
    "$$E(S) = -\\sum_{i} p_ilog_2(p_i)$$\n",
    "\n",
    "Parameters:\n",
    "* **data** is the data whose entropy we want to find.\n",
    "\n",
    "retuns:<br>\n",
    "It return the `entropy` of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(data):\n",
    "    n = len(data)\n",
    "    if n == 0: return 0\n",
    "    attr1 = sum([1 for row in data if row[-1] == 'e'])\n",
    "    attr2 = n - attr1\n",
    "    if attr1 & attr2 != 0:\n",
    "        entrpy = -(attr1/n)*log2(attr1/n)-(attr2/n)*log2(attr2/n)\n",
    "        return entrpy\n",
    "    return -(attr2/n)*log2(attr2/n) if attr1 == 0 else -(attr1/n)*log2(attr1/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**homogeneous**<br>\n",
    "The `homogeneous` is a helper function for `id3 algorithm`. It check if the given dataset has all class labels of the same type or not.\n",
    "\n",
    "Parameters:\n",
    "* **data** is the data we want to check.\n",
    "\n",
    "retuns:<br>\n",
    "It returns `majority class label` if the data is homogeneours, otherwise it returns `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def homogeneous(data):\n",
    "    count = {'e':0, 'p':0}\n",
    "    count['e'] = sum([1 for row in data if row[-1] == 'e'])\n",
    "    count['p'] = sum([1 for row in data if row[-1] == 'p'])\n",
    "    if count['e']== 0 or count['p'] == 0:\n",
    "        return 'p' if count['e'] == 0 else 'e'\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**majority_label**<br>\n",
    "The `majority_label` is a helper function for `id3 algorithm`. It finds the majority class label in the data.\n",
    "Parameters:\n",
    "* **data** is the data we want to find majority class for.\n",
    "\n",
    "retuns:<br>\n",
    "It returnns `majority class label` for the givend data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_label(data):\n",
    "    count = {'e':0, 'p':0}\n",
    "    count['e'] = sum([1 for row in data if row[-1] == 'e'])\n",
    "    count['p'] = sum([1 for row in data if row[-1] == 'p'])\n",
    "    return 'e' if count['e'] > count['p'] else 'p'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**filter_data**<br>\n",
    "The `filter_data` is a helper function for `id3 algorithm`. It creates a new list of data that maches that condition that attribute = attribute value.\n",
    "\n",
    "Parameters:\n",
    "* **data** is the data we want to filter.\n",
    "\n",
    "retuns:<br>\n",
    "It returns `filtered data` that mahces the condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(data, attr, attr_val):\n",
    "    filtered_data =  [row for row in data if row[attr] == attr_val]\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pick_best_attributes**<br>\n",
    "The `pick_best_attributes` is a helper function for `id3 algorithm`. it finds the best attribute from the attribuets list by calculating the information gain for each attribute. The below function was used to calculte the information gain.\n",
    "$$ G(S,A) = E(S) -\\sum_{v \\epsilon V_A} \\frac{|S_v|}{|S|}E(S_v) $$\n",
    "\n",
    "\n",
    "Parameters:\n",
    "* **data** is the data we want to filter.\n",
    "* **attributes** is the dictionary of attributes and its domain values.\n",
    "\n",
    "\n",
    "retuns:<br>\n",
    "It returns `filtered data` that mahces the condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_best_attributes(data, attributes):\n",
    "    start_entrpy = entropy(data)\n",
    "    info_gain = []\n",
    "    attr_list = list(attributes.keys())[:-1]\n",
    "    for attr in attr_list:\n",
    "        attr_entropy = []\n",
    "        for attr_val in attributes[attr]:\n",
    "            f_data = filter_data(data, attr, attr_val)\n",
    "            attr_entropy += [(len(f_data)/len(data))*entropy(f_data)]\n",
    "        info_gain += [start_entrpy - sum(attr_entropy)]\n",
    "    best_attr_indx = info_gain.index(max(info_gain))\n",
    "    return attr_list[best_attr_indx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**id3**<br>\n",
    "The `id3` is the algorithm that train the decision tree and creates a tree.\n",
    "\n",
    "Parameters:\n",
    "* **data** is the data used to train.\n",
    "* **attributes** is the dictionary of attributes and its domain values.\n",
    "* **default** is majority class.\n",
    "\n",
    "\n",
    "retuns:<br>\n",
    "It returns a trained `tree`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def id3(data, attributes, default):\n",
    "    if len(data) == 0:\n",
    "        return default\n",
    "    if homogeneous(data) != False:\n",
    "        return homogeneous(data)\n",
    "    if not attributes:\n",
    "        return majority_label(data)\n",
    "    best_attr = pick_best_attributes(data, attributes)\n",
    "    node = {best_attr: {val:None for val in attributes[best_attr]}}  # create a new node\n",
    "    default_label = majority_label(data)\n",
    "    for val in attributes[best_attr]:\n",
    "        subset = filter_data(data, best_attr, val)\n",
    "        attr_copy =  {attr: attributes[attr] for attr in attributes if attr != best_attr}\n",
    "        child = id3(subset, attr_copy, default_label)\n",
    "        node[best_attr][val] = child   # add child to node \n",
    "    return node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train**<br>\n",
    "The `train` is the function that prepares the required data for `id3 algorithm`.\n",
    "\n",
    "Parameters:\n",
    "* **data** is the data used to train.\n",
    "\n",
    "retuns:<br>\n",
    "It returns a trained `tree`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data):\n",
    "    attributes = get_attribute_metadata(data)\n",
    "    tree = id3(data, attributes, default = 'p')\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**predict**<br>\n",
    "The `predict` is the recursive function used to predic the class label for the given test.\n",
    "\n",
    "Parameters:\n",
    "* **tree** is trained decision tree.\n",
    "* **test** is the test point we want to predict the class label.\n",
    "\n",
    "\n",
    "retuns:<br>\n",
    "It returns the predicted `class label`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tree, test):\n",
    "    num = list(tree.keys())[0]\n",
    "    return tree[num][test[num]] if type(tree[num][test[num]]) == str else predict(tree[num][test[num]], test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**classify**<br>\n",
    "The `classify` function that makes a call to the `predict` for each test point we want to test.\n",
    "\n",
    "Parameters:\n",
    "* **tree** is trained decision tree.\n",
    "* **test_data** is the test points we want to predict the class label.\n",
    "\n",
    "\n",
    "retuns:<br>\n",
    "It returns the predicted `class label` for each testpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree, test_data):\n",
    "    if type(test_data) == list and type(test_data[0]) == list:\n",
    "        return [predict(tree, test) for test in test_data]\n",
    "    else:\n",
    "        return predict(tree, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**evaluate**<br>\n",
    "The `evaluate` function that calculates the error rate between the predicted and the actuaal. The below equation is used to calculate the erorr rate.\n",
    "$$error\\_rate=\\frac{errors}{n}$$\n",
    "\n",
    "Parameters:\n",
    "* **actual** is the actual test label for the each test observation.\n",
    "* **predicted** is the class labels that were predicted by our model.\n",
    "\n",
    "retuns:<br>\n",
    "It returns the `error rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(actual, predicted):\n",
    "    result  = [1 for i in range(len(predicted)) if actual[i] != predicted[i]]\n",
    "    error_rate = sum(result)/len(actual)\n",
    "    return error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cross_validate**<br>\n",
    "The `cross_validate` check the accuracy of our model by running the 10 fold cross validation. It prints the error rate of each fold and the averate error rate of 10 folds.\n",
    "\n",
    "Parameters:\n",
    "* **data** is data we want to use for cross validation.\n",
    "* **cross_validate** indicates what percent(as decimal) of the data we want to use to train the model.\n",
    "\n",
    "retuns:<br>\n",
    "It does not return anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(data, train_percent=.8):\n",
    "    errors = []\n",
    "    for test_nun in range(10):\n",
    "        train_data = random.sample(data, int(len(data)*train_percent))\n",
    "        test_data = [row[:-1] for row in data if row not in train_data]\n",
    "        test_label = [row[-1] for row in data if row not in train_data]\n",
    "\n",
    "        tree = train(train_data)\n",
    "        predicted = classify(tree, test_data)\n",
    "        error_rate = evaluate(test_label, predicted)\n",
    "        errors += [error_rate]\n",
    "        print(f\"Test# {test_nun+1:2}: Error Rate:{round(error_rate*100,3)}%\")\n",
    "    print(f\"Average Error Rate: {round((sum(errors)/ len(errors))*100, 3)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree representation:\n",
      "{4: {'a': 'e',\n",
      "     'c': 'p',\n",
      "     'f': 'p',\n",
      "     'l': 'e',\n",
      "     'm': 'p',\n",
      "     'n': {19: {'b': 'e',\n",
      "                'h': 'e',\n",
      "                'k': 'e',\n",
      "                'n': 'e',\n",
      "                'o': 'e',\n",
      "                'r': 'p',\n",
      "                'u': 'e',\n",
      "                'w': {14: {'b': 'e',\n",
      "                           'c': 'e',\n",
      "                           'e': 'e',\n",
      "                           'g': 'e',\n",
      "                           'n': {10: {'?': 'p',\n",
      "                                      'b': 'e',\n",
      "                                      'c': 'e',\n",
      "                                      'e': 'e',\n",
      "                                      'r': 'e'}},\n",
      "                           'o': 'e',\n",
      "                           'p': 'e',\n",
      "                           'w': {7: {'b': 'e', 'n': 'p'}},\n",
      "                           'y': 'p'}},\n",
      "                'y': 'e'}},\n",
      "     'p': 'p',\n",
      "     's': 'p',\n",
      "     'y': 'p'}}\n"
     ]
    }
   ],
   "source": [
    "# read the data\n",
    "data_file = 'agaricus-lepiota.data'\n",
    "data = load_file(data_file)\n",
    "\n",
    "# Train the tree for representaiton\n",
    "tree = train(data)\n",
    "print(\"Tree representation:\")\n",
    "pprint(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test#  1: Error Rate:0.0%\n",
      "Test#  2: Error Rate:0.0%\n",
      "Test#  3: Error Rate:0.0%\n",
      "Test#  4: Error Rate:0.123%\n",
      "Test#  5: Error Rate:0.0%\n",
      "Test#  6: Error Rate:0.0%\n",
      "Test#  7: Error Rate:0.0%\n",
      "Test#  8: Error Rate:0.0%\n",
      "Test#  9: Error Rate:0.0%\n",
      "Test# 10: Error Rate:0.0%\n",
      "Average Error Rate: 0.012%\n"
     ]
    }
   ],
   "source": [
    "# run the cross validation\n",
    "cross_validate(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before You Submit...\n",
    "\n",
    "1. Did you provide output exactly as requested?\n",
    "2. Did you re-execute the entire notebook? (\"Restart Kernel and Rull All Cells...\")\n",
    "3. If you did not complete the assignment or had difficulty please explain what gave you the most difficulty in the Markdown cell below.\n",
    "4. Did you change the name of the file to `jhed_id.ipynb`?\n",
    "\n",
    "Do not submit any other files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (en605645)",
   "language": "python",
   "name": "en605645"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "81px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
